{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a40f9f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_opt = ['EdLevel','DevType','Country','AISelect']\n",
    "multi_opt = ['Employment','CodingActivities','LanguageHaveWorkedWith','DatabaseHaveWorkedWith',\n",
    "             'PlatformHaveWorkedWith','WebframeHaveWorkedWith','MiscTechHaveWorkedWith']\n",
    "number = ['YearsCode','YearsCodePro','WorkExp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "504f3e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "def map_years(arr):\n",
    "    dfy = pd.DataFrame(arr, columns=number)\n",
    "    dfy = dfy.replace({'Less than 1 year': 0.5, 'More than 50 years': 50})\n",
    "    return dfy.astype(float)\n",
    "\n",
    "def split_semi(X):\n",
    "    return X.iloc[:, 0].fillna('').str.split(';')\n",
    "\n",
    "def tokenize_list(tokens):\n",
    "    return tokens\n",
    "\n",
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "preprocessor = joblib.load(\"../models/preprocessor.pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfacffce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/processed/salary_only.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bf3f3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2040000.0\n",
       "1          28000.0\n",
       "2          85000.0\n",
       "3          50000.0\n",
       "4         110000.0\n",
       "           ...    \n",
       "33735      36000.0\n",
       "33736      40000.0\n",
       "33737      61000.0\n",
       "33738      58000.0\n",
       "33739      55000.0\n",
       "Name: CompTotal, Length: 33740, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CompTotal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6b7eaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = preprocessor.transform(df.drop(columns=['CompTotal']))\n",
    "Y = df['CompTotal']\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5db91e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<26992x446 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 685129 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e347300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LinearRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d1726e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 68\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# split, train, evaluate\u001b[39;00m\n\u001b[0;32m     67\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(df, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 68\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m preds \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest RMSE:\u001b[39m\u001b[38;5;124m\"\u001b[39m, mean_squared_error(y_test, preds))\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py:662\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    656\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    657\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_metadata_for_step(\n\u001b[0;32m    658\u001b[0m             step_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    659\u001b[0m             step_params\u001b[38;5;241m=\u001b[39mrouted_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]],\n\u001b[0;32m    660\u001b[0m             all_params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    661\u001b[0m         )\n\u001b[1;32m--> 662\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:487\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    476\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    479\u001b[0m ]\n\u001b[0;32m    481\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 487\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:189\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    187\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 189\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    197\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    198\u001b[0m         X,\n\u001b[0;32m    199\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    202\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    203\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# your column lists\n",
    "single_opt = ['EdLevel','DevType','Country','AISelect']\n",
    "multi_opt  = [\n",
    "    'Employment','CodingActivities','LanguageHaveWorkedWith',\n",
    "    'DatabaseHaveWorkedWith','PlatformHaveWorkedWith',\n",
    "    'WebframeHaveWorkedWith','MiscTechHaveWorkedWith'\n",
    "]\n",
    "number     = ['YearsCode','YearsCodePro','WorkExp']\n",
    "\n",
    "# transformer functions\n",
    "def map_years(X):\n",
    "    return X.replace({'Less than 1 year':0.5, 'More than 50 years':50}).astype(float)\n",
    "\n",
    "def split_semi(X):\n",
    "    # X is a Series\n",
    "    return X.fillna('').str.split(';')\n",
    "\n",
    "# build ColumnTransformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    # numeric years → map → impute → scale\n",
    "    ('num', Pipeline([\n",
    "        ('map',   FunctionTransformer(map_years, validate=False)),\n",
    "        ('imp',   SimpleImputer(strategy='median')),\n",
    "        ('scale', StandardScaler())\n",
    "    ]), number),\n",
    "\n",
    "    # single‐choice → impute → one‑hot\n",
    "    ('cat', Pipeline([\n",
    "        ('imp', SimpleImputer(strategy='constant', fill_value='Missing')),\n",
    "        ('ohe', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ]), single_opt),\n",
    "\n",
    "    # multi‐choice → split → vectorize\n",
    "    *[\n",
    "      (col, Pipeline([\n",
    "           ('split', FunctionTransformer(lambda df, c=col: split_semi(df[c]), validate=False)),\n",
    "           ('vec',   CountVectorizer(tokenizer=lambda x: x,\n",
    "                                     preprocessor=lambda x: x,\n",
    "                                     token_pattern=None,\n",
    "                                     binary=True))\n",
    "       ]), [col])\n",
    "      for col in multi_opt\n",
    "    ]\n",
    "], remainder='drop')\n",
    "\n",
    "# full end‑to‑end pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('pre', preprocessor),\n",
    "    ('rf',  RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# load & prepare\n",
    "df = pd.read_csv(\"../data/raw/survey_results_public.csv\")\n",
    "y  = pd.to_numeric(df['CompTotal'], errors='coerce').fillna(0)\n",
    "\n",
    "# split, train, evaluate\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2, random_state=42)\n",
    "pipeline.fit(X_train, y_train)\n",
    "preds = pipeline.predict(X_test)\n",
    "\n",
    "print(\"Test RMSE:\", mean_squared_error(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe14498",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "# Custom Transformer for multi-select categorical features\n",
    "class MultiSelectTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Custom transformer for multi-select categorical features.\n",
    "    It splits the string by a delimiter and then applies a multi-hot encoding.\n",
    "    \"\"\"\n",
    "    def __init__(self, delimiter=';'):\n",
    "        self.delimiter = delimiter\n",
    "        self.categories_ = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Find all unique categories\n",
    "        all_categories = set()\n",
    "        for _, row in X.items():\n",
    "            if pd.notna(row):\n",
    "                all_categories.update(cat.strip() for cat in row.split(self.delimiter))\n",
    "        self.categories_ = sorted(list(all_categories))\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # Create the multi-hot encoded matrix\n",
    "        num_samples = len(X)\n",
    "        num_categories = len(self.categories_)\n",
    "        encoded_matrix = np.zeros((num_samples, num_categories))\n",
    "\n",
    "        for i, row in enumerate(X):\n",
    "            if pd.notna(row):\n",
    "                for j, cat in enumerate(self.categories_):\n",
    "                    if cat in [c.strip() for c in row.split(self.delimiter)]:\n",
    "                        encoded_matrix[i, j] = 1\n",
    "        return encoded_matrix\n",
    "\n",
    "# Select features for the model\n",
    "# These would be chosen based on the EDA and domain knowledge\n",
    "features = [\n",
    "    'Country', 'EdLevel', 'YearsCodePro', 'DevType',\n",
    "    'LanguageHaveWorkedWith', 'WebframeHaveWorkedWith',\n",
    "    'DatabaseHaveWorkedWith', 'PlatformHaveWorkedWith'\n",
    "]\n",
    "target = 'ConvertedCompYearly'\n",
    "\n",
    "# Drop rows where target is missing\n",
    "df_model = df.dropna(subset=[target] + features).copy()\n",
    "\n",
    "# Split the data\n",
    "X = df_model[features]\n",
    "y = df_model[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Define which columns go to which transformer\n",
    "numerical_features = ['YearsCodePro']\n",
    "categorical_features = ['Country', 'EdLevel', 'DevType']\n",
    "multi_select_features = [\n",
    "    'LanguageHaveWorkedWith', 'WebframeHaveWorkedWith',\n",
    "    'DatabaseHaveWorkedWith', 'PlatformHaveWorkedWith'\n",
    "]\n",
    "\n",
    "# Create the preprocessing pipelines for each feature type\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "multi_select_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='')),\n",
    "    ('multi_hot', MultiSelectTransformer())\n",
    "])\n",
    "\n",
    "# Create the master preprocessor with ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "        ('multi', multi_select_transformer, multi_select_features[0]), # Example for one multi-select, expand as needed\n",
    "        # You can add more multi-select features here\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0818bc05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                            MacOS;Windows\n",
       "1                                Other Linux-based;Windows\n",
       "2                                                    MacOS\n",
       "3                                                    MacOS\n",
       "4                                            MacOS;Windows\n",
       "                               ...                        \n",
       "33735                                                  NaN\n",
       "33736                                          iOS;Windows\n",
       "33737                                                 Arch\n",
       "33738                                                MacOS\n",
       "33739    Cygwin;Debian;iOS;iPadOS;MacOS;Ubuntu;Windows;...\n",
       "Name: OpSysPersonal use, Length: 33740, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['OpSysPersonal use']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffe0bd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResponseId\tMainBranch\tAge\tEmployment\tRemoteWork\tCheck\tCodingActivities\tEdLevel\tLearnCode\tLearnCodeOnline\tTechDoc\tYearsCode\tYearsCodePro\tDevType\tOrgSize\tPurchaseInfluence\tBuyNewTool\tBuildvsBuy\tTechEndorse\tCountry\tCurrency\tCompTotal\tLanguageHaveWorkedWith\tLanguageWantToWorkWith\tLanguageAdmired\tDatabaseHaveWorkedWith\tDatabaseWantToWorkWith\tDatabaseAdmired\tPlatformHaveWorkedWith\tPlatformWantToWorkWith\tPlatformAdmired\tWebframeHaveWorkedWith\tWebframeWantToWorkWith\tWebframeAdmired\tEmbeddedHaveWorkedWith\tEmbeddedWantToWorkWith\tEmbeddedAdmired\tMiscTechHaveWorkedWith\tMiscTechWantToWorkWith\tMiscTechAdmired\tToolsTechHaveWorkedWith\tToolsTechWantToWorkWith\tToolsTechAdmired\tNEWCollabToolsHaveWorkedWith\tNEWCollabToolsWantToWorkWith\tNEWCollabToolsAdmired\tOpSysPersonal use\tOpSysProfessional use\tOfficeStackAsyncHaveWorkedWith\tOfficeStackAsyncWantToWorkWith\tOfficeStackAsyncAdmired\tOfficeStackSyncHaveWorkedWith\tOfficeStackSyncWantToWorkWith\tOfficeStackSyncAdmired\tAISearchDevHaveWorkedWith\tAISearchDevWantToWorkWith\tAISearchDevAdmired\tNEWSOSites\tSOVisitFreq\tSOAccount\tSOPartFreq\tSOHow\tSOComm\tAISelect\tAISent\tAIBen\tAIAcc\tAIComplex\tAIToolCurrently Using\tAIToolInterested in Using\tAIToolNot interested in Using\tAINextMuch more integrated\tAINextNo change\tAINextMore integrated\tAINextLess integrated\tAINextMuch less integrated\tAIThreat\tAIEthics\tAIChallenges\tTBranch\tICorPM\tWorkExp\tKnowledge_1\tKnowledge_2\tKnowledge_3\tKnowledge_4\tKnowledge_5\tKnowledge_6\tKnowledge_7\tKnowledge_8\tKnowledge_9\tFrequency_1\tFrequency_2\tFrequency_3\tTimeSearching\tTimeAnswering\tFrustration\tProfessionalTech\tProfessionalCloud\tProfessionalQuestion\tIndustry\tJobSatPoints_1\tJobSatPoints_4\tJobSatPoints_5\tJobSatPoints_6\tJobSatPoints_7\tJobSatPoints_8\tJobSatPoints_9\tJobSatPoints_10\tJobSatPoints_11\tSurveyLength\tSurveyEase\tConvertedCompYearly\tJobSat\t"
     ]
    }
   ],
   "source": [
    "for i in df.columns:\n",
    "    print(i,end='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57eaeacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing DagsHub and MLflow...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as malhar.c.prajapati\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as malhar.c.prajapati\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository malhar.c.prajapati/Stack-overflow-survey-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-salary-prediction initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository malhar.c.prajapati/Stack-overflow-survey-\u001b[1;36m2024\u001b[0m-salary-prediction initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data loaded successfully.\n",
      "Dataset shape: (65437, 114)\n",
      "Defining features and preprocessing pipeline...\n",
      "Splitting data and starting model training...\n",
      "Fitting the model pipeline...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003598 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 655\n",
      "[LightGBM] [Info] Number of data points in the train set: 18748, number of used features: 304\n",
      "[LightGBM] [Info] Start training from score 10.786639\n",
      "Model training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics (on log-transformed salary):\n",
      "  RMSE: 1.0486\n",
      "  MAE: 0.5866\n",
      "  R2 Score: 0.4479\n",
      "Generating and logging feature importance plot...\n",
      "Feature importance plot logged.\n",
      "Logging model to MLflow...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/27 14:04:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'stackoverflow-salary-predictor' already exists. Creating a new version of this model...\n",
      "2025/07/27 14:04:59 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: stackoverflow-salary-predictor, version 2\n",
      "Created version '2' of model 'stackoverflow-salary-predictor'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logged successfully.\n",
      "🏃 View run LGBM Regressor Run at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0/runs/3199f3dbfe614ad59f363c7eecd51379\n",
      "🧪 View experiment at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0\n",
      "\n",
      "✅ Training script finished. View the run in DagsHub/MLflow: mlflow-artifacts:/b66ac9a49b554a539f4bb427870fb357/3199f3dbfe614ad59f363c7eecd51379/artifacts\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import dagshub\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer, MultiLabelBinarizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import seaborn as sns\n",
    "\n",
    "# df = pd.read_csv(\"../data/processed/salary_only.csv\")\n",
    "\n",
    "print(\"Initializing DagsHub and MLflow...\")\n",
    "\n",
    "DAGSHUB_REPO_OWNER = os.getenv(\"DAGSHUB_REPO_OWNER\", \"malhar.c.prajapati\")\n",
    "DAGSHUB_REPO_NAME = os.getenv(\"DAGSHUB_REPO_NAME\", \"Stack-overflow-survey-2024-salary-prediction\")\n",
    "\n",
    "dagshub.init(repo_owner=DAGSHUB_REPO_OWNER, repo_name=DAGSHUB_REPO_NAME, mlflow=True)\n",
    "mlflow.set_experiment(\"Salary Prediction Experiments\")\n",
    "\n",
    "\n",
    "print(\"Loading data...\")\n",
    "\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv('../data/raw/survey_results_public.csv')\n",
    "    print(\"Data loaded successfully.\")\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'survey_results_public.csv' not found. Please place it in the same directory.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "print(\"Defining features and preprocessing pipeline...\")\n",
    "\n",
    "\n",
    "\n",
    "FEATURE_COLUMNS = [\n",
    "    'Country', 'EdLevel', 'YearsCodePro', 'MainBranch', 'RemoteWork', 'Age',\n",
    "    'LanguageHaveWorkedWith', 'DatabaseHaveWorkedWith', 'WebframeHaveWorkedWith',\n",
    "    'OpSysPersonal use' \n",
    "]\n",
    "TARGET_COLUMN = 'ConvertedCompYearly'\n",
    "\n",
    "\n",
    "\n",
    "df_model = df.dropna(subset=[TARGET_COLUMN]).copy()\n",
    "\n",
    "df_model.dropna(subset=FEATURE_COLUMNS, how='all', inplace=True)\n",
    "\n",
    "\n",
    "df_model['YearsCodePro'] = pd.to_numeric(df_model['YearsCodePro'], errors='coerce')\n",
    "\n",
    "\n",
    "df_model[TARGET_COLUMN] = np.log1p(df_model[TARGET_COLUMN])\n",
    "\n",
    "X = df_model[FEATURE_COLUMNS]\n",
    "y = df_model[TARGET_COLUMN]\n",
    "\n",
    "\n",
    "class MultiSelectBinarizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.mlb = None\n",
    "        self.classes_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        series = X.fillna('').astype(str).apply(lambda x: x.split(';'))\n",
    "        self.mlb = MultiLabelBinarizer(sparse_output=False)\n",
    "        self.mlb.fit(series)\n",
    "        self.classes_ = self.mlb.classes_\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        series = X.fillna('').astype(str).apply(lambda x: x.split(';'))\n",
    "        encoded_matrix = self.mlb.transform(series)\n",
    "        df = pd.DataFrame(encoded_matrix, columns=self.classes_, index=X.index)\n",
    "        if '' in df.columns:\n",
    "            df = df.drop(columns=[''])\n",
    "        return df\n",
    "\n",
    "\n",
    "\n",
    "numerical_features = ['YearsCodePro']\n",
    "categorical_features = ['Country', 'EdLevel', 'MainBranch', 'RemoteWork', 'OpSysPersonal use', 'Age']\n",
    "multi_select_features = ['LanguageHaveWorkedWith', 'DatabaseHaveWorkedWith', 'WebframeHaveWorkedWith']\n",
    "\n",
    "\n",
    "numerical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_pipeline, numerical_features),\n",
    "        ('cat', categorical_pipeline, categorical_features),\n",
    "        \n",
    "        ('lang', MultiSelectBinarizer(), 'LanguageHaveWorkedWith'),\n",
    "        ('db', MultiSelectBinarizer(), 'DatabaseHaveWorkedWith'),\n",
    "        ('web', MultiSelectBinarizer(), 'WebframeHaveWorkedWith')\n",
    "    ],\n",
    "    remainder='drop', \n",
    "    n_jobs=-1 \n",
    ")\n",
    "\n",
    "\n",
    "print(\"Splitting data and starting model training...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "with mlflow.start_run(run_name=\"LGBM Regressor Run\") as run:\n",
    "    \n",
    "    mlflow.log_param(\"model_class\", \"LGBMRegressor\")\n",
    "\n",
    "    \n",
    "    lgbm_params = {\n",
    "        'n_estimators': 250,\n",
    "        'learning_rate': 0.05,\n",
    "        'num_leaves': 31,\n",
    "        'max_depth': -1,\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1,\n",
    "        'colsample_bytree': 0.8\n",
    "    }\n",
    "    mlflow.log_params(lgbm_params)\n",
    "\n",
    "    \n",
    "    model = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', LGBMRegressor(**lgbm_params))\n",
    "    ])\n",
    "\n",
    "    \n",
    "    print(\"Fitting the model pipeline...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"Model training complete.\")\n",
    "\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Evaluation Metrics (on log-transformed salary):\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  MAE: {mae:.4f}\")\n",
    "    print(f\"  R2 Score: {r2:.4f}\")\n",
    "\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "\n",
    "    \n",
    "    try:\n",
    "        print(\"Generating and logging feature importance plot...\")\n",
    "        \n",
    "        ohe_feature_names = list(model.named_steps['preprocessor'].named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(categorical_features))\n",
    "        lang_feature_names = list(model.named_steps['preprocessor'].named_transformers_['lang'].classes_)\n",
    "        db_feature_names = list(model.named_steps['preprocessor'].named_transformers_['db'].classes_)\n",
    "        web_feature_names = list(model.named_steps['preprocessor'].named_transformers_['web'].classes_)\n",
    "\n",
    "        \n",
    "        feature_names = numerical_features + ohe_feature_names + lang_feature_names + db_feature_names + web_feature_names\n",
    "        \n",
    "        \n",
    "        feature_names = [f for f in feature_names if f != '']\n",
    "\n",
    "        importances = model.named_steps['regressor'].feature_importances_\n",
    "\n",
    "        \n",
    "        if len(feature_names) == len(importances):\n",
    "            feature_importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "            feature_importance_df = feature_importance_df.sort_values('importance', ascending=False).head(25)\n",
    "\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            sns.barplot(x='importance', y='feature', data=feature_importance_df)\n",
    "            plt.title('Top 25 Feature Importances')\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            \n",
    "            plot_path = \"feature_importance.png\"\n",
    "            plt.savefig(plot_path)\n",
    "            plt.close()\n",
    "\n",
    "            \n",
    "            mlflow.log_artifact(plot_path, \"plots\")\n",
    "            print(\"Feature importance plot logged.\")\n",
    "        else:\n",
    "            print(f\"Warning: Mismatch in feature names ({len(feature_names)}) and importances ({len(importances)}). Skipping plot.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Could not generate feature importance plot: {e}\")\n",
    "\n",
    "\n",
    "    \n",
    "    print(\"Logging model to MLflow...\")\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model,\n",
    "        artifact_path=\"salary-predictor-model\",\n",
    "        registered_model_name=\"stackoverflow-salary-predictor\" \n",
    "    )\n",
    "    print(\"Model logged successfully.\")\n",
    "\n",
    "print(f\"\\n✅ Training script finished. View the run in DagsHub/MLflow: {run.info.artifact_uri}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e72e612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual columns in X_train: ['Country', 'EdLevel', 'DevType', 'RemoteWork', 'Age', 'LanguageHaveWorkedWith', 'WebframeHaveWorkedWith', 'DatabaseHaveWorkedWith', 'PlatformHaveWorkedWith', 'OpSysPersonal use']\n",
      "Using OS column: OpSysPersonal use\n",
      "Testing preprocessor on small sample...\n",
      "Preprocessor test successful!\n"
     ]
    }
   ],
   "source": [
    "# Add this debug step before creating the pipeline\n",
    "print(\"Actual columns in X_train:\", X_train.columns.tolist())\n",
    "def split_multiselect(X):\n",
    "    \"\"\"Splits semicolon-separated strings into a binary matrix.\"\"\"\n",
    "    # Handle different input types (Series, DataFrame, or array)\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        # If it's a DataFrame, extract the first column\n",
    "        X = X.iloc[:, 0]\n",
    "    elif not isinstance(X, pd.Series):\n",
    "        # If it's not a Series, convert to Series\n",
    "        X = pd.Series(X)\n",
    "    \n",
    "    # Split the strings and binarize\n",
    "    lists = X.fillna('').str.split(';')\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    return mlb.fit_transform(lists)\n",
    "\n",
    "# Update the multi_pipeline to use this improved function\n",
    "def build_preprocessor():\n",
    "    # Ordinal pipeline for age\n",
    "    ord_age_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='Missing')),\n",
    "        ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "    ])\n",
    "\n",
    "    # Categorical pipeline\n",
    "    cat_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='Missing')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    # Multi-select pipeline\n",
    "    multi_pipeline = Pipeline([\n",
    "        ('split', FunctionTransformer(split_multiselect, validate=False))\n",
    "    ])\n",
    "\n",
    "    # Get EXACT column names from your DataFrame\n",
    "    actual_columns = X_train.columns.tolist()\n",
    "    \n",
    "    # Find the OS column - it might be named differently\n",
    "    os_columns = [col for col in actual_columns if 'OpSys' in col]\n",
    "    os_column = os_columns[0] if os_columns else None\n",
    "    \n",
    "    if not os_column:\n",
    "        raise ValueError(\"No OS column found in data\")\n",
    "    \n",
    "    print(f\"Using OS column: {os_column}\")\n",
    "\n",
    "    # Build transformer with verified columns\n",
    "    transformers = [\n",
    "        # Ordinal age\n",
    "        ('ord', ord_age_pipeline, ['Age']),\n",
    "        \n",
    "        # Categorical features\n",
    "        ('cat', cat_pipeline, [\n",
    "            'Country',\n",
    "            'EdLevel',\n",
    "            'DevType',\n",
    "            'RemoteWork',\n",
    "            os_column  # Use the actual column name\n",
    "        ]),\n",
    "        \n",
    "        # Multi-select features\n",
    "        ('lang', multi_pipeline, ['LanguageHaveWorkedWith']),\n",
    "        ('web',  multi_pipeline, ['WebframeHaveWorkedWith']),\n",
    "        ('db',   multi_pipeline, ['DatabaseHaveWorkedWith']),\n",
    "        ('plat', multi_pipeline, ['PlatformHaveWorkedWith']),\n",
    "    ]\n",
    "    \n",
    "    return ColumnTransformer(transformers, remainder='drop')\n",
    "\n",
    "# Build the preprocessor with dynamic column detection\n",
    "preprocessor = build_preprocessor()\n",
    "\n",
    "# Test the preprocessor on a small sample before full training\n",
    "try:\n",
    "    print(\"Testing preprocessor on small sample...\")\n",
    "    preprocessor.fit_transform(X_train.head())\n",
    "    print(\"Preprocessor test successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"Preprocessor error: {e}\")\n",
    "    # Print which columns are causing issues\n",
    "    for name, _, cols in preprocessor.transformers:\n",
    "        missing = [col for col in cols if col not in X_train.columns]\n",
    "        if missing:\n",
    "            print(f\"Transformer '{name}' missing columns: {missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a75feb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository malhar.c.prajapati/Stack-overflow-survey-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-salary-prediction initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository malhar.c.prajapati/Stack-overflow-survey-\u001b[1;36m2024\u001b[0m-salary-prediction initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing data...\n",
      "Data preparation complete.\n",
      "Training on 18748 samples, testing on 4687 samples.\n",
      "\n",
      "--- Starting GridSearchCV for gbr ---\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/27 19:40:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Successfully registered model 'gbr_salary_predictor'.\n",
      "2025/07/27 19:40:41 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: gbr_salary_predictor, version 1\n",
      "Created version '1' of model 'gbr_salary_predictor'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Results for gbr ---\n",
      "Best Params: {'model__max_depth': 5, 'model__n_estimators': 200}\n",
      "Metrics: {'mae': 0.6119540927268493, 'rmse': 1.075558024253791, 'r2': 0.4190943392858837}\n",
      "MLflow Run ID: a480b13f96bf4d4db5ebb319d2558e00\n",
      "🏃 View run GridSearch_gbr at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0/runs/a480b13f96bf4d4db5ebb319d2558e00\n",
      "🧪 View experiment at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0\n",
      "\n",
      "--- Starting GridSearchCV for rf ---\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/27 19:45:22 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Successfully registered model 'rf_salary_predictor'.\n",
      "2025/07/27 19:46:06 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: rf_salary_predictor, version 1\n",
      "Created version '1' of model 'rf_salary_predictor'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Results for rf ---\n",
      "Best Params: {'model__max_depth': 20, 'model__n_estimators': 200}\n",
      "Metrics: {'mae': 0.6593767852301139, 'rmse': 1.1333069639679252, 'r2': 0.3550396239549919}\n",
      "MLflow Run ID: fee8289484964d1db970c036bde5e494\n",
      "🏃 View run GridSearch_rf at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0/runs/fee8289484964d1db970c036bde5e494\n",
      "🧪 View experiment at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0\n",
      "\n",
      "--- Starting GridSearchCV for ridge ---\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/27 19:46:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Successfully registered model 'ridge_salary_predictor'.\n",
      "2025/07/27 19:46:18 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: ridge_salary_predictor, version 1\n",
      "Created version '1' of model 'ridge_salary_predictor'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Results for ridge ---\n",
      "Best Params: {'model__alpha': 10.0}\n",
      "Metrics: {'mae': 0.6247712567342067, 'rmse': 1.0665746278674635, 'r2': 0.42875762550798957}\n",
      "MLflow Run ID: 1ce59028dd0946f5a7005747e4a3bf00\n",
      "🏃 View run GridSearch_ridge at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0/runs/1ce59028dd0946f5a7005747e4a3bf00\n",
      "🧪 View experiment at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0\n",
      "\n",
      "--- All models trained and logged to MLflow. ---\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import dagshub\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "# Correctly import the builder function from your preprocessing file\n",
    "from preprocessing import build_preprocessor\n",
    "\n",
    "# --- MLflow & DagsHub Initialization ---\n",
    "dagshub.init(repo_owner='malhar.c.prajapati',\n",
    "             repo_name='Stack-overflow-survey-2024-salary-prediction',\n",
    "             mlflow=True)\n",
    "\n",
    "print(\"Loading and preparing data...\")\n",
    "# It's good practice to specify the parent directory for clarity\n",
    "df = pd.read_csv('../data/processed/features_labels.csv')\n",
    "\n",
    "# --- Data Preparation ---\n",
    "# Drop rows where the target is missing, as they cannot be used for training\n",
    "df.dropna(subset=['ConvertedCompYearly'], inplace=True)\n",
    "X = df.drop(columns=['ConvertedCompYearly'])\n",
    "# Use log1p for a more stable target variable\n",
    "y = np.log1p(df['ConvertedCompYearly'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Data preparation complete.\")\n",
    "print(f\"Training on {len(X_train)} samples, testing on {len(X_test)} samples.\")\n",
    "\n",
    "\n",
    "# --- Model and Preprocessing Setup ---\n",
    "# Build the preprocessor using your corrected function\n",
    "\n",
    "# Define the models and their hyperparameter grids for GridSearchCV\n",
    "models_and_params = {\n",
    "    'gbr': (GradientBoostingRegressor(random_state=42), {\n",
    "        'model__n_estimators': [100, 200],\n",
    "        'model__max_depth': [3, 5]\n",
    "    }),\n",
    "    'rf': (RandomForestRegressor(random_state=42), {\n",
    "        'model__n_estimators': [100, 200],\n",
    "        'model__max_depth': [10, 20]\n",
    "    }),\n",
    "    'ridge': (Ridge(), {\n",
    "        'model__alpha': [0.1, 1.0, 10.0]\n",
    "    })\n",
    "}\n",
    "\n",
    "# --- Training and Experiment Tracking Loop ---\n",
    "for model_name, (estimator, params) in models_and_params.items():\n",
    "    # Create the full pipeline: Preprocessing -> Model\n",
    "    # This is the object that will be saved and used in the backend\n",
    "    full_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', estimator)\n",
    "    ])\n",
    "\n",
    "    # Set up GridSearchCV\n",
    "    grid_search = GridSearchCV(full_pipeline, params, cv=3,\n",
    "                               scoring='neg_mean_absolute_error', n_jobs=-1, verbose=1)\n",
    "\n",
    "    print(f\"\\n--- Starting GridSearchCV for {model_name} ---\")\n",
    "    \n",
    "    # Start an MLflow run\n",
    "    with mlflow.start_run(run_name=f\"GridSearch_{model_name}\") as run:\n",
    "        mlflow.log_param(\"model_name\", model_name)\n",
    "        \n",
    "        # Train the grid search\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # Log the best parameters found by the search\n",
    "        mlflow.log_params(grid_search.best_params_)\n",
    "        \n",
    "        # Evaluate the best estimator on the test set\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred = best_model.predict(X_test)\n",
    "\n",
    "        # Calculate metrics\n",
    "        metrics = {\n",
    "            'mae': mean_absolute_error(y_test, y_pred),\n",
    "            'rmse': np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "            'r2': r2_score(y_test, y_pred)\n",
    "        }\n",
    "        \n",
    "        # Log the performance metrics\n",
    "        mlflow.log_metrics(metrics)\n",
    "        \n",
    "        # Log the best model pipeline\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=best_model,\n",
    "            artifact_path=\"model\",\n",
    "            registered_model_name=f\"{model_name}_salary_predictor\"\n",
    "        )\n",
    "        \n",
    "        print(f\"--- Results for {model_name} ---\")\n",
    "        print(f\"Best Params: {grid_search.best_params_}\")\n",
    "        print(f\"Metrics: {metrics}\")\n",
    "        print(f\"MLflow Run ID: {run.info.run_id}\")\n",
    "\n",
    "print(\"\\n--- All models trained and logged to MLflow. ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f6b95b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository malhar.c.prajapati/Stack-overflow-survey-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-salary-prediction initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository malhar.c.prajapati/Stack-overflow-survey-\u001b[1;36m2024\u001b[0m-salary-prediction initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Training on 18748 samples, testing on 4687 samples.\n",
      "Preprocessor test passed.\n",
      "\n",
      "--- Training gbr ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Temp\\ipykernel_13992\\3350753604.py:53: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = pd.Series(df[col]).replace({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Temp\\ipykernel_13992\\3350753604.py:53: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = pd.Series(df[col]).replace({\n",
      "C:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Temp\\ipykernel_13992\\3350753604.py:53: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = pd.Series(df[col]).replace({\n",
      "2025/07/27 20:30:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'gbr_salary_predictor' already exists. Creating a new version of this model...\n",
      "2025/07/27 20:30:28 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: gbr_salary_predictor, version 2\n",
      "Created version '2' of model 'gbr_salary_predictor'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for gbr: {'mae': 30708.47122212532, 'rmse': 81725.05402335647, 'r2': 0.28755861130940485}\n",
      "🏃 View run GridSearch_gbr at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0/runs/9dd6478582dd4131aa3224d19f4e4fcb\n",
      "🧪 View experiment at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0\n",
      "\n",
      "--- Training rf ---\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Temp\\ipykernel_13992\\3350753604.py:53: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = pd.Series(df[col]).replace({\n",
      "C:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Temp\\ipykernel_13992\\3350753604.py:53: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = pd.Series(df[col]).replace({\n",
      "2025/07/27 20:56:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'rf_salary_predictor' already exists. Creating a new version of this model...\n",
      "2025/07/27 21:02:12 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: rf_salary_predictor, version 2\n",
      "Created version '2' of model 'rf_salary_predictor'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for rf: {'mae': 31953.23711696943, 'rmse': 83202.54398212278, 'r2': 0.261565600891849}\n",
      "🏃 View run GridSearch_rf at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0/runs/e05c392c987e4013b1543ff9c896769c\n",
      "🧪 View experiment at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0\n",
      "\n",
      "--- Training xgb ---\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Temp\\ipykernel_13992\\3350753604.py:53: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = pd.Series(df[col]).replace({\n",
      "C:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Temp\\ipykernel_13992\\3350753604.py:53: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = pd.Series(df[col]).replace({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run GridSearch_xgb at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0/runs/503a95c3a0514793880eef8990586e6d\n",
      "🧪 View experiment at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'super' object has no attribute '__sklearn_tags__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 176\u001b[0m\n\u001b[0;32m    174\u001b[0m grid\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m    175\u001b[0m best \u001b[38;5;241m=\u001b[39m grid\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[1;32m--> 176\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mbest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;66;03m# Convert back to original scale\u001b[39;00m\n\u001b[0;32m    178\u001b[0m y_true \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpm1(y_test)\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py:782\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[1;34m(self, X, **params)\u001b[0m\n\u001b[0;32m    740\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transform the data, and apply `predict` with the final estimator.\u001b[39;00m\n\u001b[0;32m    741\u001b[0m \n\u001b[0;32m    742\u001b[0m \u001b[38;5;124;03mCall `transform` of each transformer in the pipeline. The transformed\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;124;03m    Result of calling `predict` on the final estimator.\u001b[39;00m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;66;03m# TODO(1.8): Remove the context manager and use check_is_fitted(self)\u001b[39;00m\n\u001b[1;32m--> 782\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_raise_or_warn_if_not_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    783\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _routing_enabled():\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:144\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py:60\u001b[0m, in \u001b[0;36m_raise_or_warn_if_not_fitted\u001b[1;34m(estimator)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# we only get here if the above didn't raise\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NotFittedError:\n\u001b[0;32m     62\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m     63\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis Pipeline instance is not fitted yet. Call \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     64\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mappropriate arguments before using other methods such as transform, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m     68\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1756\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1753\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tags\u001b[38;5;241m.\u001b[39mrequires_fit \u001b[38;5;129;01mand\u001b[39;00m attributes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1754\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m-> 1756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43m_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattributes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_or_any\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1757\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1665\u001b[0m, in \u001b[0;36m_is_fitted\u001b[1;34m(estimator, attributes, all_or_any)\u001b[0m\n\u001b[0;32m   1662\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m all_or_any([\u001b[38;5;28mhasattr\u001b[39m(estimator, attr) \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m attributes])\n\u001b[0;32m   1664\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sklearn_is_fitted__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1665\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__sklearn_is_fitted__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1667\u001b[0m fitted_attrs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   1668\u001b[0m     v \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(estimator) \u001b[38;5;28;01mif\u001b[39;00m v\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m v\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1669\u001b[0m ]\n\u001b[0;32m   1670\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fitted_attrs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py:1321\u001b[0m, in \u001b[0;36mPipeline.__sklearn_is_fitted__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;66;03m# check if the last step of the pipeline is fitted\u001b[39;00m\n\u001b[0;32m   1318\u001b[0m     \u001b[38;5;66;03m# we only check the last step since if the last step is fit, it\u001b[39;00m\n\u001b[0;32m   1319\u001b[0m     \u001b[38;5;66;03m# means the previous steps should also be fit. This is faster than\u001b[39;00m\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;66;03m# checking if every step of the pipeline is fit.\u001b[39;00m\n\u001b[1;32m-> 1321\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlast_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1323\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NotFittedError:\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1751\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[1;32m-> 1751\u001b[0m tags \u001b[38;5;241m=\u001b[39m \u001b[43mget_tags\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1753\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tags\u001b[38;5;241m.\u001b[39mrequires_fit \u001b[38;5;129;01mand\u001b[39;00m attributes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1754\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_tags.py:430\u001b[0m, in \u001b[0;36mget_tags\u001b[1;34m(estimator)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m klass \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39mmro()):\n\u001b[0;32m    429\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sklearn_tags__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(klass):\n\u001b[1;32m--> 430\u001b[0m         sklearn_tags_provider[klass] \u001b[38;5;241m=\u001b[39m \u001b[43mklass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__sklearn_tags__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    431\u001b[0m         class_order\u001b[38;5;241m.\u001b[39mappend(klass)\n\u001b[0;32m    432\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_more_tags\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(klass):\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:613\u001b[0m, in \u001b[0;36mRegressorMixin.__sklearn_tags__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__sklearn_tags__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 613\u001b[0m     tags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__sklearn_tags__\u001b[49m()\n\u001b[0;32m    614\u001b[0m     tags\u001b[38;5;241m.\u001b[39mestimator_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregressor\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    615\u001b[0m     tags\u001b[38;5;241m.\u001b[39mregressor_tags \u001b[38;5;241m=\u001b[39m RegressorTags()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'super' object has no attribute '__sklearn_tags__'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import dagshub\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder, StandardScaler, OrdinalEncoder,\n",
    "    FunctionTransformer, MultiLabelBinarizer\n",
    ")\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# --- Feature Configuration ---\n",
    "single_opt = ['EdLevel', 'DevType', 'Country', 'AISelect', 'RemoteWork']\n",
    "multi_opt = ['Employment', 'CodingActivities', 'LanguageHaveWorkedWith',\n",
    "             'DatabaseHaveWorkedWith', 'PlatformHaveWorkedWith',\n",
    "             'WebframeHaveWorkedWith', 'MiscTechHaveWorkedWith']\n",
    "number = ['YearsCode', 'YearsCodePro', 'WorkExp']  # Numeric fields (exclude Age)\n",
    "ordinal = ['Age']  # Ordinal age feature\n",
    "\n",
    "# --- Improved Preprocessing Functions ---\n",
    "def split_multiselect(X):\n",
    "    \"\"\"Splits semicolon-separated strings into a binary matrix.\"\"\"\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X = X.iloc[:, 0]\n",
    "    elif not isinstance(X, pd.Series):\n",
    "        X = pd.Series(X)\n",
    "    lists = X.fillna('').str.split(';')\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    return mlb.fit_transform(lists)\n",
    "\n",
    "\n",
    "def convert_numeric_years(X):\n",
    "    \"\"\"Converts special string labels to numeric for years columns, handles 1D or 2D inputs.\"\"\"\n",
    "    arr = np.array(X)\n",
    "    # Single feature case\n",
    "    if arr.ndim == 1:\n",
    "        series = pd.Series(arr).replace({\n",
    "            'Less than 1 year': 0.5,\n",
    "            'More than 50 years': 51\n",
    "        })\n",
    "        return pd.to_numeric(series, errors='coerce').values.reshape(-1, 1)\n",
    "    # Multiple features: apply to each column\n",
    "    df = pd.DataFrame(arr)\n",
    "    for col in df.columns:\n",
    "        df[col] = pd.Series(df[col]).replace({\n",
    "            'Less than 1 year': 0.5,\n",
    "            'More than 50 years': 51\n",
    "        })\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    return df.values\n",
    "\n",
    "\n",
    "def build_preprocessor():\n",
    "    \"\"\"Builds a comprehensive preprocessor handling numeric, ordinal, categorical, and multi-select features.\"\"\"\n",
    "    # Numeric pipeline: convert special strings, impute, scale\n",
    "    num_pipeline = Pipeline([\n",
    "        ('convert', FunctionTransformer(convert_numeric_years, validate=False)),\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    # Ordinal pipeline for age\n",
    "    ord_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='Missing')),\n",
    "        ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "    ])\n",
    "\n",
    "    # Single-choice categorical pipeline\n",
    "    cat_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='Missing')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    ])\n",
    "\n",
    "    # Multi-select pipeline\n",
    "    multi_pipeline = Pipeline([\n",
    "        ('split', FunctionTransformer(split_multiselect, validate=False))\n",
    "    ])\n",
    "\n",
    "    # Assemble ColumnTransformer\n",
    "    transformer_list = []\n",
    "    transformer_list.append(('num', num_pipeline, number))\n",
    "    transformer_list.append(('ord', ord_pipeline, ordinal))\n",
    "    transformer_list.append(('cat', cat_pipeline, single_opt))\n",
    "    for col in multi_opt:\n",
    "        transformer_list.append((f'multi_{col}', multi_pipeline, [col]))\n",
    "\n",
    "    return ColumnTransformer(transformers=transformer_list, remainder='drop')\n",
    "\n",
    "# --- MLflow & DagsHub Initialization ---\n",
    "dagshub.init(\n",
    "    repo_owner='malhar.c.prajapati',\n",
    "    repo_name='Stack-overflow-survey-2024-salary-prediction',\n",
    "    mlflow=True\n",
    ")\n",
    "\n",
    "# --- Data Loading & Preparation ---\n",
    "print(\"Loading data...\")\n",
    "df = pd.read_csv('../data/raw/survey_results_public.csv', low_memory=False)\n",
    "all_features = single_opt + multi_opt + number + ordinal + ['ConvertedCompYearly']\n",
    "df = df.loc[:, df.columns.intersection(all_features + ['ConvertedCompYearly'])]\n",
    "# Drop rows with missing target\n",
    "(df.dropna(subset=['ConvertedCompYearly'], inplace=True))\n",
    "X = df.drop(columns=['ConvertedCompYearly'])\n",
    "y = np.log1p(df['ConvertedCompYearly'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "print(f\"Training on {len(X_train)} samples, testing on {len(X_test)} samples.\")\n",
    "\n",
    "# --- Preprocessor Test ---\n",
    "preprocessor = build_preprocessor()\n",
    "try:\n",
    "    preprocessor.fit_transform(X_train.head())\n",
    "    print(\"Preprocessor test passed.\")\n",
    "except Exception as e:\n",
    "    print(f\"Preprocessor error: {e}\")\n",
    "\n",
    "# --- Model & Hyperparameter Configuration ---\n",
    "models_and_params = {\n",
    "    'gbr': (GradientBoostingRegressor(random_state=42), {\n",
    "        'model__n_estimators': [100, 200, 300],\n",
    "        'model__max_depth': [3, 5, 7],\n",
    "        'model__learning_rate': [0.1, 0.05],\n",
    "        'model__subsample': [0.8, 1.0]\n",
    "    }),\n",
    "    'rf': (RandomForestRegressor(random_state=42), {\n",
    "        'model__n_estimators': [100, 200, 300],\n",
    "        'model__max_depth': [10, 20, None],\n",
    "        'model__min_samples_split': [2, 5],\n",
    "        'model__min_samples_leaf': [1, 2]\n",
    "    }),\n",
    "    'xgb': (XGBRegressor(random_state=42, eval_metric='mae'), {\n",
    "        'model__n_estimators': [100, 200],\n",
    "        'model__max_depth': [3, 5, 7],\n",
    "        'model__learning_rate': [0.1, 0.05],\n",
    "        'model__subsample': [0.8, 1.0],\n",
    "        'model__colsample_bytree': [0.8, 1.0]\n",
    "    }),\n",
    "    'lgbm': (LGBMRegressor(random_state=42), {\n",
    "        'model__n_estimators': [100, 200],\n",
    "        'model__max_depth': [3, 5, -1],\n",
    "        'model__learning_rate': [0.1, 0.05],\n",
    "        'model__num_leaves': [31, 63],\n",
    "        'model__subsample': [0.8, 1.0]\n",
    "    }),\n",
    "    'elasticnet': (ElasticNet(random_state=42), {\n",
    "        'model__alpha': [0.1, 1.0, 10.0],\n",
    "        'model__l1_ratio': [0.2, 0.5, 0.8]\n",
    "    })\n",
    "}\n",
    "\n",
    "# --- Training Loop ---\n",
    "for model_name, (estimator, params) in models_and_params.items():\n",
    "    full_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('selector', SelectKBest(score_func=f_regression, k='all')),\n",
    "        ('model', estimator)\n",
    "    ])\n",
    "    grid = GridSearchCV(\n",
    "        full_pipeline, params, cv=3,\n",
    "        scoring='neg_mean_absolute_error', verbose=1, n_jobs=-1\n",
    "    )\n",
    "    print(f\"\\n--- Training {model_name} ---\")\n",
    "    with mlflow.start_run(run_name=f\"GridSearch_{model_name}\") as run:\n",
    "        mlflow.log_param('model', model_name)\n",
    "        grid.fit(X_train, y_train)\n",
    "        best = grid.best_estimator_\n",
    "        y_pred = best.predict(X_test)\n",
    "        # Convert back to original scale\n",
    "        y_true = np.expm1(y_test)\n",
    "        y_pred_orig = np.expm1(y_pred)\n",
    "        metrics = {\n",
    "            'mae': mean_absolute_error(y_true, y_pred_orig),\n",
    "            'rmse': np.sqrt(mean_squared_error(y_true, y_pred_orig)),\n",
    "            'r2': r2_score(y_true, y_pred_orig)\n",
    "        }\n",
    "        mlflow.log_params(grid.best_params_)\n",
    "        mlflow.log_metrics(metrics)\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=best,\n",
    "            artifact_path='model',\n",
    "            registered_model_name=f\"{model_name}_salary_predictor\"\n",
    "        )\n",
    "        print(f\"Results for {model_name}: {metrics}\")\n",
    "print(\"\\nAll models complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348c5b96",
   "metadata": {},
   "source": [
    "### Exp-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5142cbd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as malhar.c.prajapati\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as malhar.c.prajapati\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository malhar.c.prajapati/Stack-overflow-survey-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-salary-prediction initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository malhar.c.prajapati/Stack-overflow-survey-\u001b[1;36m2024\u001b[0m-salary-prediction initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-processed data...\n",
      "Data loaded. Training on 18748 samples, testing on 4687 samples.\n",
      "\n",
      "--- Starting GridSearchCV for xgb ---\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "--- Results for xgb ---\n",
      "Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
      "Metrics: {'mae': 24424.664173338646, 'rmse': 34636.882065153375, 'r2': 0.641098601225861}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/31 19:31:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'xgb_salary_predictor_processed' already exists. Creating a new version of this model...\n",
      "2025/07/31 19:32:05 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: xgb_salary_predictor_processed, version 2\n",
      "Created version '2' of model 'xgb_salary_predictor_processed'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run GridSearch_xgb_on_processed_data at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0/runs/42889009b4d14b6e833bf27f9879839d\n",
      "🧪 View experiment at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0\n",
      "\n",
      "--- Starting GridSearchCV for rf ---\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "--- Results for rf ---\n",
      "Best Params: {'max_depth': 20, 'min_samples_leaf': 4, 'n_estimators': 200}\n",
      "Metrics: {'mae': 25945.204901618305, 'rmse': 36336.52970706808, 'r2': 0.6050114875211025}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/31 19:32:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'rf_salary_predictor_processed' already exists. Creating a new version of this model...\n",
      "2025/07/31 19:35:01 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: rf_salary_predictor_processed, version 3\n",
      "Created version '3' of model 'rf_salary_predictor_processed'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run GridSearch_rf_on_processed_data at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0/runs/ed83afc2a4d84f958f371fd9783dc1fe\n",
      "🧪 View experiment at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0\n",
      "\n",
      "--- Starting GridSearchCV for lgbm ---\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000976 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1661\n",
      "[LightGBM] [Info] Number of data points in the train set: 18748, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 77627.108065\n",
      "--- Results for lgbm ---\n",
      "Best Params: {'learning_rate': 0.05, 'n_estimators': 200, 'num_leaves': 60}\n",
      "Metrics: {'mae': 24288.446540825695, 'rmse': 34620.81134140928, 'r2': 0.6414315680994465}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/31 19:35:19 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'lgbm_salary_predictor_processed' already exists. Creating a new version of this model...\n",
      "2025/07/31 19:35:26 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: lgbm_salary_predictor_processed, version 3\n",
      "Created version '3' of model 'lgbm_salary_predictor_processed'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run GridSearch_lgbm_on_processed_data at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0/runs/8a8ed8e59aaf4a1f84b187d57cf4aab6\n",
      "🧪 View experiment at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0\n",
      "\n",
      "--- Starting GridSearchCV for gbr ---\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "--- Results for gbr ---\n",
      "Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
      "Metrics: {'mae': 24521.71021744618, 'rmse': 34775.58970738377, 'r2': 0.6382183161863455}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/31 19:35:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Successfully registered model 'gbr_salary_predictor_processed'.\n",
      "2025/07/31 19:36:01 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: gbr_salary_predictor_processed, version 1\n",
      "Created version '1' of model 'gbr_salary_predictor_processed'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run GridSearch_gbr_on_processed_data at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0/runs/d391a7bdba1b4efc97fe8abdc20eeec2\n",
      "🧪 View experiment at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0\n",
      "\n",
      "--- All model training experiments are complete. ---\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import dagshub\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "dagshub.init(\n",
    "    repo_owner='malhar.c.prajapati',\n",
    "    repo_name='Stack-overflow-survey-2024-salary-prediction',\n",
    "    mlflow=True\n",
    ")\n",
    "\n",
    "print(\"Loading pre-processed data...\")\n",
    "# Assuming 'final_dataset.csv' is in a 'data/processed' subdirectory relative to the script\n",
    "df = pd.read_csv('../data/processed/final_dataset.csv', index_col=0)\n",
    "X = df.drop(columns=['ConvertedCompYearly'])\n",
    "y = df['ConvertedCompYearly'] \n",
    "\n",
    "if len(X) != len(y):\n",
    "    raise ValueError(\n",
    "        f\"Mismatch in number of samples between processed features ({len(X)}) \"\n",
    "        f\"and target variable ({len(y)}). Please regenerate processed.csv.\"\n",
    "    )\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "print(f\"Data loaded. Training on {len(X_train)} samples, testing on {len(X_test)} samples.\")\n",
    "\n",
    "models_and_params = {\n",
    "    'xgb': (XGBRegressor(random_state=42, n_jobs=-1, eval_metric='mae'), {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.05, 0.1],\n",
    "        'max_depth': [3, 5]\n",
    "    }),\n",
    "    'rf': (RandomForestRegressor(random_state=42, n_jobs=-1), {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [10, 20],\n",
    "        'min_samples_leaf': [2, 4]\n",
    "    }),\n",
    "    'lgbm': (LGBMRegressor(random_state=42, n_jobs=-1), {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.05, 0.1],\n",
    "        'num_leaves': [31, 60]\n",
    "    }),\n",
    "    'gbr': (GradientBoostingRegressor(random_state=42), {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.05, 0.1],\n",
    "        'max_depth': [3, 5]\n",
    "    })\n",
    "}\n",
    "\n",
    "for model_name, (estimator, params) in models_and_params.items():\n",
    "    \n",
    "    full_pipeline = Pipeline([\n",
    "        ('model', estimator)\n",
    "    ])\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=estimator, \n",
    "        param_grid=params, \n",
    "        cv=3,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        verbose=1, \n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n--- Starting GridSearchCV for {model_name} ---\")\n",
    "    \n",
    "    with mlflow.start_run(run_name=f\"GridSearch_{model_name}_on_processed_data\") as run:\n",
    "        mlflow.log_param('model_name', model_name)\n",
    "        \n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        \n",
    "        # The model predicts on the same scale as the training data.\n",
    "        # Since 'y_train' appears to be the original salary, 'y_pred' will be too.\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        \n",
    "        # FIX: The error was caused by applying np.expm1 to the original salary values,\n",
    "        # which caused a numeric overflow. The target variable 'y' is already on the\n",
    "        # original scale, so we can calculate metrics directly without transformation.\n",
    "        \n",
    "        metrics = {\n",
    "            'mae': mean_absolute_error(y_test, y_pred),\n",
    "            'rmse': np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "            'r2': r2_score(y_test, y_pred)\n",
    "        }\n",
    "        \n",
    "        print(f\"--- Results for {model_name} ---\")\n",
    "        print(f\"Best Params: {grid_search.best_params_}\")\n",
    "        print(f\"Metrics: {metrics}\")\n",
    "        \n",
    "        \n",
    "        mlflow.log_params(grid_search.best_params_)\n",
    "        mlflow.log_metrics(metrics)\n",
    "        \n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=best_model,\n",
    "            artifact_path='model',\n",
    "            registered_model_name=f\"{model_name}_salary_predictor_processed\"\n",
    "        )\n",
    "\n",
    "print(\"\\n--- All model training experiments are complete. ---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cbdbfb",
   "metadata": {},
   "source": [
    "1.1 Where we added 1 more column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c99053aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository malhar.c.prajapati/Stack-overflow-survey-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-salary-prediction initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository malhar.c.prajapati/Stack-overflow-survey-\u001b[1;36m2024\u001b[0m-salary-prediction initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-processed data...\n",
      "Data loaded. Training on 18748 samples, testing on 4687 samples.\n",
      "\n",
      "--- Starting GridSearchCV for xgb ---\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "--- Results for xgb ---\n",
      "Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
      "Metrics: {'mae': 24153.799660886354, 'rmse': 34384.392642434046, 'r2': 0.6463120334776091}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'xgb_salary_predictor_processed' already exists. Creating a new version of this model...\n",
      "2025/07/31 21:09:03 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: xgb_salary_predictor_processed, version 3\n",
      "Created version '3' of model 'xgb_salary_predictor_processed'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run GridSearch_xgb_on_processed_data at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0/runs/5dc4d0250b454cc383772eb2951d6df2\n",
      "🧪 View experiment at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0\n",
      "\n",
      "--- Starting GridSearchCV for rf ---\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "--- Results for rf ---\n",
      "Best Params: {'max_depth': 20, 'min_samples_leaf': 4, 'n_estimators': 200}\n",
      "Metrics: {'mae': 25825.046018947633, 'rmse': 36229.57622105682, 'r2': 0.6073332956747615}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'rf_salary_predictor_processed' already exists. Creating a new version of this model...\n",
      "2025/07/31 21:12:19 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: rf_salary_predictor_processed, version 4\n",
      "Created version '4' of model 'rf_salary_predictor_processed'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run GridSearch_rf_on_processed_data at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0/runs/dc37c107fd504905acf4bfca1043a97b\n",
      "🧪 View experiment at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0\n",
      "\n",
      "--- Starting GridSearchCV for lgbm ---\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1888\n",
      "[LightGBM] [Info] Number of data points in the train set: 18748, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 77627.108065\n",
      "--- Results for lgbm ---\n",
      "Best Params: {'learning_rate': 0.05, 'n_estimators': 200, 'num_leaves': 31}\n",
      "Metrics: {'mae': 24192.365091005893, 'rmse': 34522.2372346251, 'r2': 0.6434705292156202}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'lgbm_salary_predictor_processed' already exists. Creating a new version of this model...\n",
      "2025/07/31 21:12:48 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: lgbm_salary_predictor_processed, version 4\n",
      "Created version '4' of model 'lgbm_salary_predictor_processed'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run GridSearch_lgbm_on_processed_data at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0/runs/046e9bfc7eba4583a798ab2b1f83ed3f\n",
      "🧪 View experiment at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0\n",
      "\n",
      "--- Starting GridSearchCV for gbr ---\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "--- Results for gbr ---\n",
      "Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
      "Metrics: {'mae': 24120.810023335376, 'rmse': 34380.76423639723, 'r2': 0.6463866752405156}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'gbr_salary_predictor_processed' already exists. Creating a new version of this model...\n",
      "2025/07/31 21:13:35 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: gbr_salary_predictor_processed, version 2\n",
      "Created version '2' of model 'gbr_salary_predictor_processed'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run GridSearch_gbr_on_processed_data at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0/runs/92b60943c4834c549dc31c26d5b90f7d\n",
      "🧪 View experiment at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0\n",
      "\n",
      "--- All model training experiments are complete. ---\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import dagshub\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "dagshub.init(\n",
    "    repo_owner='malhar.c.prajapati',\n",
    "    repo_name='Stack-overflow-survey-2024-salary-prediction',\n",
    "    mlflow=True\n",
    ")\n",
    "\n",
    "print(\"Loading pre-processed data...\")\n",
    "# Assuming 'final_dataset.csv' is in a 'data/processed' subdirectory relative to the script\n",
    "df = pd.read_csv(\"final_dataset.csv\", index_col=0)\n",
    "X = df.drop(columns=['ConvertedCompYearly'])\n",
    "y = df['ConvertedCompYearly'] \n",
    "\n",
    "if len(X) != len(y):\n",
    "    raise ValueError(\n",
    "        f\"Mismatch in number of samples between processed features ({len(X)}) \"\n",
    "        f\"and target variable ({len(y)}). Please regenerate processed.csv.\"\n",
    "    )\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "print(f\"Data loaded. Training on {len(X_train)} samples, testing on {len(X_test)} samples.\")\n",
    "\n",
    "models_and_params = {\n",
    "    'xgb': (XGBRegressor(random_state=42, n_jobs=-1, eval_metric='mae'), {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.05, 0.1],\n",
    "        'max_depth': [3, 5]\n",
    "    }),\n",
    "    'rf': (RandomForestRegressor(random_state=42, n_jobs=-1), {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [10, 20],\n",
    "        'min_samples_leaf': [2, 4]\n",
    "    }),\n",
    "    'lgbm': (LGBMRegressor(random_state=42, n_jobs=-1), {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.05, 0.1],\n",
    "        'num_leaves': [31, 60]\n",
    "    }),\n",
    "    'gbr': (GradientBoostingRegressor(random_state=42), {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.05, 0.1],\n",
    "        'max_depth': [3, 5]\n",
    "    })\n",
    "}\n",
    "\n",
    "for model_name, (estimator, params) in models_and_params.items():\n",
    "    \n",
    "    full_pipeline = Pipeline([\n",
    "        ('model', estimator)\n",
    "    ])\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=estimator, \n",
    "        param_grid=params, \n",
    "        cv=3,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        verbose=1, \n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n--- Starting GridSearchCV for {model_name} ---\")\n",
    "    \n",
    "    with mlflow.start_run(run_name=f\"GridSearch_{model_name}_on_processed_data\") as run:\n",
    "        mlflow.log_param('model_name', model_name)\n",
    "        \n",
    "        # Log which database feature was used in the model training\n",
    "        mlflow.log_param(\"database_feature_name\", \"DatabaseHaveWorkedWith\")\n",
    "        \n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        \n",
    "        # The model predicts on the same scale as the training data.\n",
    "        # Since 'y_train' appears to be the original salary, 'y_pred' will be too.\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        \n",
    "        metrics = {\n",
    "            'mae': mean_absolute_error(y_test, y_pred),\n",
    "            'rmse': np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "            'r2': r2_score(y_test, y_pred)\n",
    "        }\n",
    "        \n",
    "        print(f\"--- Results for {model_name} ---\")\n",
    "        print(f\"Best Params: {grid_search.best_params_}\")\n",
    "        print(f\"Metrics: {metrics}\")\n",
    "        \n",
    "        \n",
    "        mlflow.log_params(grid_search.best_params_)\n",
    "        mlflow.log_metrics(metrics)\n",
    "        \n",
    "        # Add an input_example to log the model signature and resolve the warning.\n",
    "        # This helps MLflow understand the model's input schema.\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=best_model,\n",
    "            artifact_path='model',\n",
    "            registered_model_name=f\"{model_name}_salary_predictor_processed\",\n",
    "            input_example=X_train.head()\n",
    "        )\n",
    "\n",
    "print(\"\\n--- All model training experiments are complete. ---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dadd71",
   "metadata": {},
   "source": [
    "### Exp-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5524c853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository malhar.c.prajapati/Stack-overflow-survey-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-salary-prediction initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository malhar.c.prajapati/Stack-overflow-survey-\u001b[1;36m2024\u001b[0m-salary-prediction initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-processed data from ../data/processed/final_dataset.csv...\n",
      "Printing size of X and y (23435, 24) (23435,)\n",
      "Data split. Training on 18748 samples, testing on 4687 samples.\n",
      "\n",
      "--- All model training experiments are complete. ---\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import dagshub\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from typing import Dict, Any, Tuple, List\n",
    "\n",
    "\n",
    "DATA_PATH = \"../data/processed/final_dataset.csv\"\n",
    "TARGET_COLUMN = 'ConvertedCompYearly'\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "\n",
    "MODELS_AND_PARAMS = {\n",
    "    'xgb': (XGBRegressor(random_state=RANDOM_STATE, n_jobs=-1, eval_metric='mae'), {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'subsample': [0.7, 1.0],\n",
    "        'colsample_bytree': [0.7, 1.0]\n",
    "    }),\n",
    "    'rf': (RandomForestRegressor(random_state=RANDOM_STATE, n_jobs=-1), {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [10, 20, 30],\n",
    "        'min_samples_leaf': [2, 4, 6],\n",
    "        'max_features': ['sqrt', 'log2']\n",
    "    }),\n",
    "    'lgbm': (LGBMRegressor(random_state=RANDOM_STATE, n_jobs=-1), {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'num_leaves': [31, 60, 90],\n",
    "        'reg_alpha': [0.1, 0.5],\n",
    "        'reg_lambda': [0.1, 0.5]\n",
    "    }),\n",
    "    'gbr': (GradientBoostingRegressor(random_state=RANDOM_STATE), {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'subsample': [0.7, 1.0]\n",
    "    })\n",
    "}\n",
    "\n",
    "def load_data(path: str) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "    \"\"\"Loads the preprocessed dataset from a CSV file.\"\"\"\n",
    "    print(f\"Loading pre-processed data from {path}...\")\n",
    "    try:\n",
    "        df = pd.read_csv(path, index_col=0)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {path} was not found.\")\n",
    "        raise\n",
    "        \n",
    "    X = df.drop(columns=[TARGET_COLUMN])\n",
    "    y = df[TARGET_COLUMN]\n",
    "\n",
    "    if len(X) != len(y):\n",
    "        raise ValueError(\n",
    "            f\"Mismatch in number of samples between features ({len(X)}) \"\n",
    "            f\"and target ({len(y)}).\"\n",
    "        )\n",
    "    return X, y\n",
    "\n",
    "def train_and_log_model(\n",
    "    model_name: str, \n",
    "    estimator: Any, \n",
    "    params: Dict[str, Any], \n",
    "    X_train: pd.DataFrame, \n",
    "    y_train: pd.Series, \n",
    "    X_test: pd.DataFrame, \n",
    "    y_test: pd.Series\n",
    ") -> None:\n",
    "    \"\"\"Performs GridSearchCV, logs results and artifacts to MLflow.\"\"\"\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=estimator, \n",
    "        param_grid=params, \n",
    "        cv=3,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        verbose=1, \n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n--- Starting GridSearchCV for {model_name} ---\")\n",
    "    \n",
    "    with mlflow.start_run(run_name=f\"GridSearch_{model_name}_final\") as run:\n",
    "        \n",
    "        mlflow.set_tag(\"model_name\", model_name)\n",
    "        mlflow.log_param(\"cv_folds\", 3)\n",
    "        \n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        \n",
    "        y_pred = best_model.predict(X_test)\n",
    "        \n",
    "        \n",
    "        metrics = {\n",
    "            'mae': mean_absolute_error(y_test, y_pred),\n",
    "            'rmse': np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "            'r2': r2_score(y_test, y_pred)\n",
    "        }\n",
    "        \n",
    "        print(f\"--- Results for {model_name} ---\")\n",
    "        print(f\"Best Params: {grid_search.best_params_}\")\n",
    "        print(f\"Metrics: {metrics}\")\n",
    "        \n",
    "        \n",
    "        mlflow.log_params(grid_search.best_params_)\n",
    "        mlflow.log_metrics(metrics)\n",
    "        \n",
    "        if hasattr(best_model, 'feature_importances_'):\n",
    "            feature_imp = pd.DataFrame(sorted(zip(best_model.feature_importances_, X_train.columns)), columns=['Value','Feature'])\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False).head(15))\n",
    "            plt.title(f'Feature Importance for {model_name}')\n",
    "            plt.tight_layout()\n",
    "            mlflow.log_figure(plt.gcf(), \"feature_importance.png\")\n",
    "            plt.close()\n",
    "\n",
    "        \n",
    "        plt.figure(figsize=(10, 10))\n",
    "        sns.scatterplot(x=y_test, y=y_pred)\n",
    "        plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--r', linewidth=2)\n",
    "        plt.xlabel('Actual Salary')\n",
    "        plt.ylabel('Predicted Salary')\n",
    "        plt.title('Actual vs. Predicted Salary')\n",
    "        mlflow.log_figure(plt.gcf(), \"actual_vs_predicted.png\")\n",
    "        plt.close()\n",
    "\n",
    "        \n",
    "        residuals = y_test - y_pred\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.histplot(residuals, kde=True)\n",
    "        plt.xlabel('Residuals')\n",
    "        plt.title('Distribution of Residuals')\n",
    "        mlflow.log_figure(plt.gcf(), \"residuals_distribution.png\")\n",
    "        plt.close()\n",
    "\n",
    "        \n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=best_model,\n",
    "            artifact_path='model',\n",
    "            registered_model_name=f\"{model_name}_salary_predictor_final\",\n",
    "            input_example=X_train.head()\n",
    "        )\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the training pipeline.\"\"\"\n",
    "    dagshub.init(\n",
    "        repo_owner='malhar.c.prajapati',\n",
    "        repo_name='Stack-overflow-survey-2024-salary-prediction',\n",
    "        mlflow=True\n",
    "    )\n",
    "    \n",
    "    X, y = load_data(DATA_PATH)\n",
    "    print(\"Printing size of X and y\",X.shape,y.shape)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
    "    )\n",
    "    print(f\"Data split. Training on {len(X_train)} samples, testing on {len(X_test)} samples.\")\n",
    "\n",
    "    for model_name, (estimator, params) in MODELS_AND_PARAMS.items():\n",
    "        train_and_log_model(model_name, estimator, params, X_train, y_train, X_test, y_test)\n",
    "\n",
    "    print(\"\\n--- All model training experiments are complete. ---\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51e0aef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
