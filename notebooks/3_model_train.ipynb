{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a40f9f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_opt = ['EdLevel','DevType','Country','AISelect']\n",
    "multi_opt = ['Employment','CodingActivities','LanguageHaveWorkedWith','DatabaseHaveWorkedWith',\n",
    "             'PlatformHaveWorkedWith','WebframeHaveWorkedWith','MiscTechHaveWorkedWith']\n",
    "number = ['YearsCode','YearsCodePro','WorkExp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "504f3e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "def map_years(arr):\n",
    "    dfy = pd.DataFrame(arr, columns=number)\n",
    "    dfy = dfy.replace({'Less than 1 year': 0.5, 'More than 50 years': 50})\n",
    "    return dfy.astype(float)\n",
    "\n",
    "def split_semi(X):\n",
    "    return X.iloc[:, 0].fillna('').str.split(';')\n",
    "\n",
    "def tokenize_list(tokens):\n",
    "    return tokens\n",
    "\n",
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "preprocessor = joblib.load(\"../models/preprocessor.pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfacffce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/processed/salary_only.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bf3f3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2040000.0\n",
       "1          28000.0\n",
       "2          85000.0\n",
       "3          50000.0\n",
       "4         110000.0\n",
       "           ...    \n",
       "33735      36000.0\n",
       "33736      40000.0\n",
       "33737      61000.0\n",
       "33738      58000.0\n",
       "33739      55000.0\n",
       "Name: CompTotal, Length: 33740, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CompTotal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6b7eaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = preprocessor.transform(df.drop(columns=['CompTotal']))\n",
    "Y = df['CompTotal']\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5db91e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<26992x446 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 685129 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e347300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LinearRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d1726e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 68\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# split, train, evaluate\u001b[39;00m\n\u001b[0;32m     67\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(df, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 68\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m preds \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest RMSE:\u001b[39m\u001b[38;5;124m\"\u001b[39m, mean_squared_error(y_test, preds))\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py:662\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    656\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    657\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_metadata_for_step(\n\u001b[0;32m    658\u001b[0m             step_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    659\u001b[0m             step_params\u001b[38;5;241m=\u001b[39mrouted_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]],\n\u001b[0;32m    660\u001b[0m             all_params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    661\u001b[0m         )\n\u001b[1;32m--> 662\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:487\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    476\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    479\u001b[0m ]\n\u001b[0;32m    481\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 487\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:189\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    187\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 189\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    197\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    198\u001b[0m         X,\n\u001b[0;32m    199\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    202\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    203\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# your column lists\n",
    "single_opt = ['EdLevel','DevType','Country','AISelect']\n",
    "multi_opt  = [\n",
    "    'Employment','CodingActivities','LanguageHaveWorkedWith',\n",
    "    'DatabaseHaveWorkedWith','PlatformHaveWorkedWith',\n",
    "    'WebframeHaveWorkedWith','MiscTechHaveWorkedWith'\n",
    "]\n",
    "number     = ['YearsCode','YearsCodePro','WorkExp']\n",
    "\n",
    "# transformer functions\n",
    "def map_years(X):\n",
    "    return X.replace({'Less than 1 year':0.5, 'More than 50 years':50}).astype(float)\n",
    "\n",
    "def split_semi(X):\n",
    "    # X is a Series\n",
    "    return X.fillna('').str.split(';')\n",
    "\n",
    "# build ColumnTransformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    # numeric years → map → impute → scale\n",
    "    ('num', Pipeline([\n",
    "        ('map',   FunctionTransformer(map_years, validate=False)),\n",
    "        ('imp',   SimpleImputer(strategy='median')),\n",
    "        ('scale', StandardScaler())\n",
    "    ]), number),\n",
    "\n",
    "    # single‐choice → impute → one‑hot\n",
    "    ('cat', Pipeline([\n",
    "        ('imp', SimpleImputer(strategy='constant', fill_value='Missing')),\n",
    "        ('ohe', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ]), single_opt),\n",
    "\n",
    "    # multi‐choice → split → vectorize\n",
    "    *[\n",
    "      (col, Pipeline([\n",
    "           ('split', FunctionTransformer(lambda df, c=col: split_semi(df[c]), validate=False)),\n",
    "           ('vec',   CountVectorizer(tokenizer=lambda x: x,\n",
    "                                     preprocessor=lambda x: x,\n",
    "                                     token_pattern=None,\n",
    "                                     binary=True))\n",
    "       ]), [col])\n",
    "      for col in multi_opt\n",
    "    ]\n",
    "], remainder='drop')\n",
    "\n",
    "# full end‑to‑end pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('pre', preprocessor),\n",
    "    ('rf',  RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# load & prepare\n",
    "df = pd.read_csv(\"../data/raw/survey_results_public.csv\")\n",
    "y  = pd.to_numeric(df['CompTotal'], errors='coerce').fillna(0)\n",
    "\n",
    "# split, train, evaluate\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2, random_state=42)\n",
    "pipeline.fit(X_train, y_train)\n",
    "preds = pipeline.predict(X_test)\n",
    "\n",
    "print(\"Test RMSE:\", mean_squared_error(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe14498",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "# Custom Transformer for multi-select categorical features\n",
    "class MultiSelectTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Custom transformer for multi-select categorical features.\n",
    "    It splits the string by a delimiter and then applies a multi-hot encoding.\n",
    "    \"\"\"\n",
    "    def __init__(self, delimiter=';'):\n",
    "        self.delimiter = delimiter\n",
    "        self.categories_ = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Find all unique categories\n",
    "        all_categories = set()\n",
    "        for _, row in X.items():\n",
    "            if pd.notna(row):\n",
    "                all_categories.update(cat.strip() for cat in row.split(self.delimiter))\n",
    "        self.categories_ = sorted(list(all_categories))\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # Create the multi-hot encoded matrix\n",
    "        num_samples = len(X)\n",
    "        num_categories = len(self.categories_)\n",
    "        encoded_matrix = np.zeros((num_samples, num_categories))\n",
    "\n",
    "        for i, row in enumerate(X):\n",
    "            if pd.notna(row):\n",
    "                for j, cat in enumerate(self.categories_):\n",
    "                    if cat in [c.strip() for c in row.split(self.delimiter)]:\n",
    "                        encoded_matrix[i, j] = 1\n",
    "        return encoded_matrix\n",
    "\n",
    "# Select features for the model\n",
    "# These would be chosen based on the EDA and domain knowledge\n",
    "features = [\n",
    "    'Country', 'EdLevel', 'YearsCodePro', 'DevType',\n",
    "    'LanguageHaveWorkedWith', 'WebframeHaveWorkedWith',\n",
    "    'DatabaseHaveWorkedWith', 'PlatformHaveWorkedWith'\n",
    "]\n",
    "target = 'ConvertedCompYearly'\n",
    "\n",
    "# Drop rows where target is missing\n",
    "df_model = df.dropna(subset=[target] + features).copy()\n",
    "\n",
    "# Split the data\n",
    "X = df_model[features]\n",
    "y = df_model[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Define which columns go to which transformer\n",
    "numerical_features = ['YearsCodePro']\n",
    "categorical_features = ['Country', 'EdLevel', 'DevType']\n",
    "multi_select_features = [\n",
    "    'LanguageHaveWorkedWith', 'WebframeHaveWorkedWith',\n",
    "    'DatabaseHaveWorkedWith', 'PlatformHaveWorkedWith'\n",
    "]\n",
    "\n",
    "# Create the preprocessing pipelines for each feature type\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "multi_select_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='')),\n",
    "    ('multi_hot', MultiSelectTransformer())\n",
    "])\n",
    "\n",
    "# Create the master preprocessor with ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "        ('multi', multi_select_transformer, multi_select_features[0]), # Example for one multi-select, expand as needed\n",
    "        # You can add more multi-select features here\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0818bc05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                            MacOS;Windows\n",
       "1                                Other Linux-based;Windows\n",
       "2                                                    MacOS\n",
       "3                                                    MacOS\n",
       "4                                            MacOS;Windows\n",
       "                               ...                        \n",
       "33735                                                  NaN\n",
       "33736                                          iOS;Windows\n",
       "33737                                                 Arch\n",
       "33738                                                MacOS\n",
       "33739    Cygwin;Debian;iOS;iPadOS;MacOS;Ubuntu;Windows;...\n",
       "Name: OpSysPersonal use, Length: 33740, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['OpSysPersonal use']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffe0bd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResponseId\tMainBranch\tAge\tEmployment\tRemoteWork\tCheck\tCodingActivities\tEdLevel\tLearnCode\tLearnCodeOnline\tTechDoc\tYearsCode\tYearsCodePro\tDevType\tOrgSize\tPurchaseInfluence\tBuyNewTool\tBuildvsBuy\tTechEndorse\tCountry\tCurrency\tCompTotal\tLanguageHaveWorkedWith\tLanguageWantToWorkWith\tLanguageAdmired\tDatabaseHaveWorkedWith\tDatabaseWantToWorkWith\tDatabaseAdmired\tPlatformHaveWorkedWith\tPlatformWantToWorkWith\tPlatformAdmired\tWebframeHaveWorkedWith\tWebframeWantToWorkWith\tWebframeAdmired\tEmbeddedHaveWorkedWith\tEmbeddedWantToWorkWith\tEmbeddedAdmired\tMiscTechHaveWorkedWith\tMiscTechWantToWorkWith\tMiscTechAdmired\tToolsTechHaveWorkedWith\tToolsTechWantToWorkWith\tToolsTechAdmired\tNEWCollabToolsHaveWorkedWith\tNEWCollabToolsWantToWorkWith\tNEWCollabToolsAdmired\tOpSysPersonal use\tOpSysProfessional use\tOfficeStackAsyncHaveWorkedWith\tOfficeStackAsyncWantToWorkWith\tOfficeStackAsyncAdmired\tOfficeStackSyncHaveWorkedWith\tOfficeStackSyncWantToWorkWith\tOfficeStackSyncAdmired\tAISearchDevHaveWorkedWith\tAISearchDevWantToWorkWith\tAISearchDevAdmired\tNEWSOSites\tSOVisitFreq\tSOAccount\tSOPartFreq\tSOHow\tSOComm\tAISelect\tAISent\tAIBen\tAIAcc\tAIComplex\tAIToolCurrently Using\tAIToolInterested in Using\tAIToolNot interested in Using\tAINextMuch more integrated\tAINextNo change\tAINextMore integrated\tAINextLess integrated\tAINextMuch less integrated\tAIThreat\tAIEthics\tAIChallenges\tTBranch\tICorPM\tWorkExp\tKnowledge_1\tKnowledge_2\tKnowledge_3\tKnowledge_4\tKnowledge_5\tKnowledge_6\tKnowledge_7\tKnowledge_8\tKnowledge_9\tFrequency_1\tFrequency_2\tFrequency_3\tTimeSearching\tTimeAnswering\tFrustration\tProfessionalTech\tProfessionalCloud\tProfessionalQuestion\tIndustry\tJobSatPoints_1\tJobSatPoints_4\tJobSatPoints_5\tJobSatPoints_6\tJobSatPoints_7\tJobSatPoints_8\tJobSatPoints_9\tJobSatPoints_10\tJobSatPoints_11\tSurveyLength\tSurveyEase\tConvertedCompYearly\tJobSat\t"
     ]
    }
   ],
   "source": [
    "for i in df.columns:\n",
    "    print(i,end='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57eaeacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing DagsHub and MLflow...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as malhar.c.prajapati\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as malhar.c.prajapati\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository malhar.c.prajapati/Stack-overflow-survey-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-salary-prediction initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository malhar.c.prajapati/Stack-overflow-survey-\u001b[1;36m2024\u001b[0m-salary-prediction initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data loaded successfully.\n",
      "Dataset shape: (65437, 114)\n",
      "Defining features and preprocessing pipeline...\n",
      "Splitting data and starting model training...\n",
      "Fitting the model pipeline...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003598 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 655\n",
      "[LightGBM] [Info] Number of data points in the train set: 18748, number of used features: 304\n",
      "[LightGBM] [Info] Start training from score 10.786639\n",
      "Model training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics (on log-transformed salary):\n",
      "  RMSE: 1.0486\n",
      "  MAE: 0.5866\n",
      "  R2 Score: 0.4479\n",
      "Generating and logging feature importance plot...\n",
      "Feature importance plot logged.\n",
      "Logging model to MLflow...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/27 14:04:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'stackoverflow-salary-predictor' already exists. Creating a new version of this model...\n",
      "2025/07/27 14:04:59 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: stackoverflow-salary-predictor, version 2\n",
      "Created version '2' of model 'stackoverflow-salary-predictor'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logged successfully.\n",
      "🏃 View run LGBM Regressor Run at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0/runs/3199f3dbfe614ad59f363c7eecd51379\n",
      "🧪 View experiment at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0\n",
      "\n",
      "✅ Training script finished. View the run in DagsHub/MLflow: mlflow-artifacts:/b66ac9a49b554a539f4bb427870fb357/3199f3dbfe614ad59f363c7eecd51379/artifacts\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import dagshub\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer, MultiLabelBinarizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import seaborn as sns\n",
    "\n",
    "# df = pd.read_csv(\"../data/processed/salary_only.csv\")\n",
    "\n",
    "print(\"Initializing DagsHub and MLflow...\")\n",
    "\n",
    "DAGSHUB_REPO_OWNER = os.getenv(\"DAGSHUB_REPO_OWNER\", \"malhar.c.prajapati\")\n",
    "DAGSHUB_REPO_NAME = os.getenv(\"DAGSHUB_REPO_NAME\", \"Stack-overflow-survey-2024-salary-prediction\")\n",
    "\n",
    "dagshub.init(repo_owner=DAGSHUB_REPO_OWNER, repo_name=DAGSHUB_REPO_NAME, mlflow=True)\n",
    "mlflow.set_experiment(\"Salary Prediction Experiments\")\n",
    "\n",
    "\n",
    "print(\"Loading data...\")\n",
    "\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv('../data/raw/survey_results_public.csv')\n",
    "    print(\"Data loaded successfully.\")\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'survey_results_public.csv' not found. Please place it in the same directory.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "print(\"Defining features and preprocessing pipeline...\")\n",
    "\n",
    "\n",
    "\n",
    "FEATURE_COLUMNS = [\n",
    "    'Country', 'EdLevel', 'YearsCodePro', 'MainBranch', 'RemoteWork', 'Age',\n",
    "    'LanguageHaveWorkedWith', 'DatabaseHaveWorkedWith', 'WebframeHaveWorkedWith',\n",
    "    'OpSysPersonal use' \n",
    "]\n",
    "TARGET_COLUMN = 'ConvertedCompYearly'\n",
    "\n",
    "\n",
    "\n",
    "df_model = df.dropna(subset=[TARGET_COLUMN]).copy()\n",
    "\n",
    "df_model.dropna(subset=FEATURE_COLUMNS, how='all', inplace=True)\n",
    "\n",
    "\n",
    "df_model['YearsCodePro'] = pd.to_numeric(df_model['YearsCodePro'], errors='coerce')\n",
    "\n",
    "\n",
    "df_model[TARGET_COLUMN] = np.log1p(df_model[TARGET_COLUMN])\n",
    "\n",
    "X = df_model[FEATURE_COLUMNS]\n",
    "y = df_model[TARGET_COLUMN]\n",
    "\n",
    "\n",
    "class MultiSelectBinarizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.mlb = None\n",
    "        self.classes_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        series = X.fillna('').astype(str).apply(lambda x: x.split(';'))\n",
    "        self.mlb = MultiLabelBinarizer(sparse_output=False)\n",
    "        self.mlb.fit(series)\n",
    "        self.classes_ = self.mlb.classes_\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        series = X.fillna('').astype(str).apply(lambda x: x.split(';'))\n",
    "        encoded_matrix = self.mlb.transform(series)\n",
    "        df = pd.DataFrame(encoded_matrix, columns=self.classes_, index=X.index)\n",
    "        if '' in df.columns:\n",
    "            df = df.drop(columns=[''])\n",
    "        return df\n",
    "\n",
    "\n",
    "\n",
    "numerical_features = ['YearsCodePro']\n",
    "categorical_features = ['Country', 'EdLevel', 'MainBranch', 'RemoteWork', 'OpSysPersonal use', 'Age']\n",
    "multi_select_features = ['LanguageHaveWorkedWith', 'DatabaseHaveWorkedWith', 'WebframeHaveWorkedWith']\n",
    "\n",
    "\n",
    "numerical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_pipeline, numerical_features),\n",
    "        ('cat', categorical_pipeline, categorical_features),\n",
    "        \n",
    "        ('lang', MultiSelectBinarizer(), 'LanguageHaveWorkedWith'),\n",
    "        ('db', MultiSelectBinarizer(), 'DatabaseHaveWorkedWith'),\n",
    "        ('web', MultiSelectBinarizer(), 'WebframeHaveWorkedWith')\n",
    "    ],\n",
    "    remainder='drop', \n",
    "    n_jobs=-1 \n",
    ")\n",
    "\n",
    "\n",
    "print(\"Splitting data and starting model training...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "with mlflow.start_run(run_name=\"LGBM Regressor Run\") as run:\n",
    "    \n",
    "    mlflow.log_param(\"model_class\", \"LGBMRegressor\")\n",
    "\n",
    "    \n",
    "    lgbm_params = {\n",
    "        'n_estimators': 250,\n",
    "        'learning_rate': 0.05,\n",
    "        'num_leaves': 31,\n",
    "        'max_depth': -1,\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1,\n",
    "        'colsample_bytree': 0.8\n",
    "    }\n",
    "    mlflow.log_params(lgbm_params)\n",
    "\n",
    "    \n",
    "    model = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', LGBMRegressor(**lgbm_params))\n",
    "    ])\n",
    "\n",
    "    \n",
    "    print(\"Fitting the model pipeline...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"Model training complete.\")\n",
    "\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Evaluation Metrics (on log-transformed salary):\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  MAE: {mae:.4f}\")\n",
    "    print(f\"  R2 Score: {r2:.4f}\")\n",
    "\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "\n",
    "    \n",
    "    try:\n",
    "        print(\"Generating and logging feature importance plot...\")\n",
    "        \n",
    "        ohe_feature_names = list(model.named_steps['preprocessor'].named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(categorical_features))\n",
    "        lang_feature_names = list(model.named_steps['preprocessor'].named_transformers_['lang'].classes_)\n",
    "        db_feature_names = list(model.named_steps['preprocessor'].named_transformers_['db'].classes_)\n",
    "        web_feature_names = list(model.named_steps['preprocessor'].named_transformers_['web'].classes_)\n",
    "\n",
    "        \n",
    "        feature_names = numerical_features + ohe_feature_names + lang_feature_names + db_feature_names + web_feature_names\n",
    "        \n",
    "        \n",
    "        feature_names = [f for f in feature_names if f != '']\n",
    "\n",
    "        importances = model.named_steps['regressor'].feature_importances_\n",
    "\n",
    "        \n",
    "        if len(feature_names) == len(importances):\n",
    "            feature_importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "            feature_importance_df = feature_importance_df.sort_values('importance', ascending=False).head(25)\n",
    "\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            sns.barplot(x='importance', y='feature', data=feature_importance_df)\n",
    "            plt.title('Top 25 Feature Importances')\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            \n",
    "            plot_path = \"feature_importance.png\"\n",
    "            plt.savefig(plot_path)\n",
    "            plt.close()\n",
    "\n",
    "            \n",
    "            mlflow.log_artifact(plot_path, \"plots\")\n",
    "            print(\"Feature importance plot logged.\")\n",
    "        else:\n",
    "            print(f\"Warning: Mismatch in feature names ({len(feature_names)}) and importances ({len(importances)}). Skipping plot.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Could not generate feature importance plot: {e}\")\n",
    "\n",
    "\n",
    "    \n",
    "    print(\"Logging model to MLflow...\")\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model,\n",
    "        artifact_path=\"salary-predictor-model\",\n",
    "        registered_model_name=\"stackoverflow-salary-predictor\" \n",
    "    )\n",
    "    print(\"Model logged successfully.\")\n",
    "\n",
    "print(f\"\\n✅ Training script finished. View the run in DagsHub/MLflow: {run.info.artifact_uri}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e72e612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual columns in X_train: ['Country', 'EdLevel', 'DevType', 'RemoteWork', 'Age', 'LanguageHaveWorkedWith', 'WebframeHaveWorkedWith', 'DatabaseHaveWorkedWith', 'PlatformHaveWorkedWith', 'OpSysPersonal use']\n",
      "Using OS column: OpSysPersonal use\n",
      "Testing preprocessor on small sample...\n",
      "Preprocessor test successful!\n"
     ]
    }
   ],
   "source": [
    "# Add this debug step before creating the pipeline\n",
    "print(\"Actual columns in X_train:\", X_train.columns.tolist())\n",
    "def split_multiselect(X):\n",
    "    \"\"\"Splits semicolon-separated strings into a binary matrix.\"\"\"\n",
    "    # Handle different input types (Series, DataFrame, or array)\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        # If it's a DataFrame, extract the first column\n",
    "        X = X.iloc[:, 0]\n",
    "    elif not isinstance(X, pd.Series):\n",
    "        # If it's not a Series, convert to Series\n",
    "        X = pd.Series(X)\n",
    "    \n",
    "    # Split the strings and binarize\n",
    "    lists = X.fillna('').str.split(';')\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    return mlb.fit_transform(lists)\n",
    "\n",
    "# Update the multi_pipeline to use this improved function\n",
    "def build_preprocessor():\n",
    "    # Ordinal pipeline for age\n",
    "    ord_age_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='Missing')),\n",
    "        ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "    ])\n",
    "\n",
    "    # Categorical pipeline\n",
    "    cat_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='Missing')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    # Multi-select pipeline\n",
    "    multi_pipeline = Pipeline([\n",
    "        ('split', FunctionTransformer(split_multiselect, validate=False))\n",
    "    ])\n",
    "\n",
    "    # Get EXACT column names from your DataFrame\n",
    "    actual_columns = X_train.columns.tolist()\n",
    "    \n",
    "    # Find the OS column - it might be named differently\n",
    "    os_columns = [col for col in actual_columns if 'OpSys' in col]\n",
    "    os_column = os_columns[0] if os_columns else None\n",
    "    \n",
    "    if not os_column:\n",
    "        raise ValueError(\"No OS column found in data\")\n",
    "    \n",
    "    print(f\"Using OS column: {os_column}\")\n",
    "\n",
    "    # Build transformer with verified columns\n",
    "    transformers = [\n",
    "        # Ordinal age\n",
    "        ('ord', ord_age_pipeline, ['Age']),\n",
    "        \n",
    "        # Categorical features\n",
    "        ('cat', cat_pipeline, [\n",
    "            'Country',\n",
    "            'EdLevel',\n",
    "            'DevType',\n",
    "            'RemoteWork',\n",
    "            os_column  # Use the actual column name\n",
    "        ]),\n",
    "        \n",
    "        # Multi-select features\n",
    "        ('lang', multi_pipeline, ['LanguageHaveWorkedWith']),\n",
    "        ('web',  multi_pipeline, ['WebframeHaveWorkedWith']),\n",
    "        ('db',   multi_pipeline, ['DatabaseHaveWorkedWith']),\n",
    "        ('plat', multi_pipeline, ['PlatformHaveWorkedWith']),\n",
    "    ]\n",
    "    \n",
    "    return ColumnTransformer(transformers, remainder='drop')\n",
    "\n",
    "# Build the preprocessor with dynamic column detection\n",
    "preprocessor = build_preprocessor()\n",
    "\n",
    "# Test the preprocessor on a small sample before full training\n",
    "try:\n",
    "    print(\"Testing preprocessor on small sample...\")\n",
    "    preprocessor.fit_transform(X_train.head())\n",
    "    print(\"Preprocessor test successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"Preprocessor error: {e}\")\n",
    "    # Print which columns are causing issues\n",
    "    for name, _, cols in preprocessor.transformers:\n",
    "        missing = [col for col in cols if col not in X_train.columns]\n",
    "        if missing:\n",
    "            print(f\"Transformer '{name}' missing columns: {missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a75feb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository malhar.c.prajapati/Stack-overflow-survey-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-salary-prediction initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository malhar.c.prajapati/Stack-overflow-survey-\u001b[1;36m2024\u001b[0m-salary-prediction initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing data...\n",
      "Data preparation complete.\n",
      "Training on 18748 samples, testing on 4687 samples.\n",
      "\n",
      "--- Starting GridSearchCV for gbr ---\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/27 19:40:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Successfully registered model 'gbr_salary_predictor'.\n",
      "2025/07/27 19:40:41 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: gbr_salary_predictor, version 1\n",
      "Created version '1' of model 'gbr_salary_predictor'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Results for gbr ---\n",
      "Best Params: {'model__max_depth': 5, 'model__n_estimators': 200}\n",
      "Metrics: {'mae': 0.6119540927268493, 'rmse': 1.075558024253791, 'r2': 0.4190943392858837}\n",
      "MLflow Run ID: a480b13f96bf4d4db5ebb319d2558e00\n",
      "🏃 View run GridSearch_gbr at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0/runs/a480b13f96bf4d4db5ebb319d2558e00\n",
      "🧪 View experiment at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0\n",
      "\n",
      "--- Starting GridSearchCV for rf ---\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/27 19:45:22 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Successfully registered model 'rf_salary_predictor'.\n",
      "2025/07/27 19:46:06 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: rf_salary_predictor, version 1\n",
      "Created version '1' of model 'rf_salary_predictor'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Results for rf ---\n",
      "Best Params: {'model__max_depth': 20, 'model__n_estimators': 200}\n",
      "Metrics: {'mae': 0.6593767852301139, 'rmse': 1.1333069639679252, 'r2': 0.3550396239549919}\n",
      "MLflow Run ID: fee8289484964d1db970c036bde5e494\n",
      "🏃 View run GridSearch_rf at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0/runs/fee8289484964d1db970c036bde5e494\n",
      "🧪 View experiment at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0\n",
      "\n",
      "--- Starting GridSearchCV for ridge ---\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/27 19:46:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Successfully registered model 'ridge_salary_predictor'.\n",
      "2025/07/27 19:46:18 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: ridge_salary_predictor, version 1\n",
      "Created version '1' of model 'ridge_salary_predictor'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Results for ridge ---\n",
      "Best Params: {'model__alpha': 10.0}\n",
      "Metrics: {'mae': 0.6247712567342067, 'rmse': 1.0665746278674635, 'r2': 0.42875762550798957}\n",
      "MLflow Run ID: 1ce59028dd0946f5a7005747e4a3bf00\n",
      "🏃 View run GridSearch_ridge at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0/runs/1ce59028dd0946f5a7005747e4a3bf00\n",
      "🧪 View experiment at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0\n",
      "\n",
      "--- All models trained and logged to MLflow. ---\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import dagshub\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "# Correctly import the builder function from your preprocessing file\n",
    "from preprocessing import build_preprocessor\n",
    "\n",
    "# --- MLflow & DagsHub Initialization ---\n",
    "dagshub.init(repo_owner='malhar.c.prajapati',\n",
    "             repo_name='Stack-overflow-survey-2024-salary-prediction',\n",
    "             mlflow=True)\n",
    "\n",
    "print(\"Loading and preparing data...\")\n",
    "# It's good practice to specify the parent directory for clarity\n",
    "df = pd.read_csv('../data/processed/features_labels.csv')\n",
    "\n",
    "# --- Data Preparation ---\n",
    "# Drop rows where the target is missing, as they cannot be used for training\n",
    "df.dropna(subset=['ConvertedCompYearly'], inplace=True)\n",
    "X = df.drop(columns=['ConvertedCompYearly'])\n",
    "# Use log1p for a more stable target variable\n",
    "y = np.log1p(df['ConvertedCompYearly'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Data preparation complete.\")\n",
    "print(f\"Training on {len(X_train)} samples, testing on {len(X_test)} samples.\")\n",
    "\n",
    "\n",
    "# --- Model and Preprocessing Setup ---\n",
    "# Build the preprocessor using your corrected function\n",
    "\n",
    "# Define the models and their hyperparameter grids for GridSearchCV\n",
    "models_and_params = {\n",
    "    'gbr': (GradientBoostingRegressor(random_state=42), {\n",
    "        'model__n_estimators': [100, 200],\n",
    "        'model__max_depth': [3, 5]\n",
    "    }),\n",
    "    'rf': (RandomForestRegressor(random_state=42), {\n",
    "        'model__n_estimators': [100, 200],\n",
    "        'model__max_depth': [10, 20]\n",
    "    }),\n",
    "    'ridge': (Ridge(), {\n",
    "        'model__alpha': [0.1, 1.0, 10.0]\n",
    "    })\n",
    "}\n",
    "\n",
    "# --- Training and Experiment Tracking Loop ---\n",
    "for model_name, (estimator, params) in models_and_params.items():\n",
    "    # Create the full pipeline: Preprocessing -> Model\n",
    "    # This is the object that will be saved and used in the backend\n",
    "    full_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', estimator)\n",
    "    ])\n",
    "\n",
    "    # Set up GridSearchCV\n",
    "    grid_search = GridSearchCV(full_pipeline, params, cv=3,\n",
    "                               scoring='neg_mean_absolute_error', n_jobs=-1, verbose=1)\n",
    "\n",
    "    print(f\"\\n--- Starting GridSearchCV for {model_name} ---\")\n",
    "    \n",
    "    # Start an MLflow run\n",
    "    with mlflow.start_run(run_name=f\"GridSearch_{model_name}\") as run:\n",
    "        mlflow.log_param(\"model_name\", model_name)\n",
    "        \n",
    "        # Train the grid search\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # Log the best parameters found by the search\n",
    "        mlflow.log_params(grid_search.best_params_)\n",
    "        \n",
    "        # Evaluate the best estimator on the test set\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred = best_model.predict(X_test)\n",
    "\n",
    "        # Calculate metrics\n",
    "        metrics = {\n",
    "            'mae': mean_absolute_error(y_test, y_pred),\n",
    "            'rmse': np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "            'r2': r2_score(y_test, y_pred)\n",
    "        }\n",
    "        \n",
    "        # Log the performance metrics\n",
    "        mlflow.log_metrics(metrics)\n",
    "        \n",
    "        # Log the best model pipeline\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=best_model,\n",
    "            artifact_path=\"model\",\n",
    "            registered_model_name=f\"{model_name}_salary_predictor\"\n",
    "        )\n",
    "        \n",
    "        print(f\"--- Results for {model_name} ---\")\n",
    "        print(f\"Best Params: {grid_search.best_params_}\")\n",
    "        print(f\"Metrics: {metrics}\")\n",
    "        print(f\"MLflow Run ID: {run.info.run_id}\")\n",
    "\n",
    "print(\"\\n--- All models trained and logged to MLflow. ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f6b95b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository malhar.c.prajapati/Stack-overflow-survey-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-salary-prediction initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository malhar.c.prajapati/Stack-overflow-survey-\u001b[1;36m2024\u001b[0m-salary-prediction initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Training on 18748 samples, testing on 4687 samples.\n",
      "Preprocessor test passed.\n",
      "\n",
      "--- Training gbr ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Temp\\ipykernel_13992\\3350753604.py:53: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = pd.Series(df[col]).replace({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Temp\\ipykernel_13992\\3350753604.py:53: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = pd.Series(df[col]).replace({\n",
      "C:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Temp\\ipykernel_13992\\3350753604.py:53: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = pd.Series(df[col]).replace({\n",
      "2025/07/27 20:30:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'gbr_salary_predictor' already exists. Creating a new version of this model...\n",
      "2025/07/27 20:30:28 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: gbr_salary_predictor, version 2\n",
      "Created version '2' of model 'gbr_salary_predictor'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for gbr: {'mae': 30708.47122212532, 'rmse': 81725.05402335647, 'r2': 0.28755861130940485}\n",
      "🏃 View run GridSearch_gbr at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0/runs/9dd6478582dd4131aa3224d19f4e4fcb\n",
      "🧪 View experiment at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0\n",
      "\n",
      "--- Training rf ---\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Temp\\ipykernel_13992\\3350753604.py:53: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = pd.Series(df[col]).replace({\n",
      "C:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Temp\\ipykernel_13992\\3350753604.py:53: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = pd.Series(df[col]).replace({\n",
      "2025/07/27 20:56:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'rf_salary_predictor' already exists. Creating a new version of this model...\n",
      "2025/07/27 21:02:12 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: rf_salary_predictor, version 2\n",
      "Created version '2' of model 'rf_salary_predictor'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for rf: {'mae': 31953.23711696943, 'rmse': 83202.54398212278, 'r2': 0.261565600891849}\n",
      "🏃 View run GridSearch_rf at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0/runs/e05c392c987e4013b1543ff9c896769c\n",
      "🧪 View experiment at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0\n",
      "\n",
      "--- Training xgb ---\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Temp\\ipykernel_13992\\3350753604.py:53: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = pd.Series(df[col]).replace({\n",
      "C:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Temp\\ipykernel_13992\\3350753604.py:53: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = pd.Series(df[col]).replace({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run GridSearch_xgb at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0/runs/503a95c3a0514793880eef8990586e6d\n",
      "🧪 View experiment at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'super' object has no attribute '__sklearn_tags__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 176\u001b[0m\n\u001b[0;32m    174\u001b[0m grid\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m    175\u001b[0m best \u001b[38;5;241m=\u001b[39m grid\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[1;32m--> 176\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mbest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;66;03m# Convert back to original scale\u001b[39;00m\n\u001b[0;32m    178\u001b[0m y_true \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpm1(y_test)\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py:782\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[1;34m(self, X, **params)\u001b[0m\n\u001b[0;32m    740\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transform the data, and apply `predict` with the final estimator.\u001b[39;00m\n\u001b[0;32m    741\u001b[0m \n\u001b[0;32m    742\u001b[0m \u001b[38;5;124;03mCall `transform` of each transformer in the pipeline. The transformed\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;124;03m    Result of calling `predict` on the final estimator.\u001b[39;00m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;66;03m# TODO(1.8): Remove the context manager and use check_is_fitted(self)\u001b[39;00m\n\u001b[1;32m--> 782\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_raise_or_warn_if_not_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    783\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _routing_enabled():\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:144\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py:60\u001b[0m, in \u001b[0;36m_raise_or_warn_if_not_fitted\u001b[1;34m(estimator)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# we only get here if the above didn't raise\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NotFittedError:\n\u001b[0;32m     62\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m     63\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis Pipeline instance is not fitted yet. Call \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     64\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mappropriate arguments before using other methods such as transform, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m     68\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1756\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1753\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tags\u001b[38;5;241m.\u001b[39mrequires_fit \u001b[38;5;129;01mand\u001b[39;00m attributes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1754\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m-> 1756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43m_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattributes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_or_any\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1757\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1665\u001b[0m, in \u001b[0;36m_is_fitted\u001b[1;34m(estimator, attributes, all_or_any)\u001b[0m\n\u001b[0;32m   1662\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m all_or_any([\u001b[38;5;28mhasattr\u001b[39m(estimator, attr) \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m attributes])\n\u001b[0;32m   1664\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sklearn_is_fitted__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1665\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__sklearn_is_fitted__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1667\u001b[0m fitted_attrs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   1668\u001b[0m     v \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(estimator) \u001b[38;5;28;01mif\u001b[39;00m v\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m v\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1669\u001b[0m ]\n\u001b[0;32m   1670\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fitted_attrs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py:1321\u001b[0m, in \u001b[0;36mPipeline.__sklearn_is_fitted__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;66;03m# check if the last step of the pipeline is fitted\u001b[39;00m\n\u001b[0;32m   1318\u001b[0m     \u001b[38;5;66;03m# we only check the last step since if the last step is fit, it\u001b[39;00m\n\u001b[0;32m   1319\u001b[0m     \u001b[38;5;66;03m# means the previous steps should also be fit. This is faster than\u001b[39;00m\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;66;03m# checking if every step of the pipeline is fit.\u001b[39;00m\n\u001b[1;32m-> 1321\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlast_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1323\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NotFittedError:\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1751\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[1;32m-> 1751\u001b[0m tags \u001b[38;5;241m=\u001b[39m \u001b[43mget_tags\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1753\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tags\u001b[38;5;241m.\u001b[39mrequires_fit \u001b[38;5;129;01mand\u001b[39;00m attributes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1754\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_tags.py:430\u001b[0m, in \u001b[0;36mget_tags\u001b[1;34m(estimator)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m klass \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39mmro()):\n\u001b[0;32m    429\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sklearn_tags__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(klass):\n\u001b[1;32m--> 430\u001b[0m         sklearn_tags_provider[klass] \u001b[38;5;241m=\u001b[39m \u001b[43mklass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__sklearn_tags__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    431\u001b[0m         class_order\u001b[38;5;241m.\u001b[39mappend(klass)\n\u001b[0;32m    432\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_more_tags\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(klass):\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:613\u001b[0m, in \u001b[0;36mRegressorMixin.__sklearn_tags__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__sklearn_tags__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 613\u001b[0m     tags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__sklearn_tags__\u001b[49m()\n\u001b[0;32m    614\u001b[0m     tags\u001b[38;5;241m.\u001b[39mestimator_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregressor\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    615\u001b[0m     tags\u001b[38;5;241m.\u001b[39mregressor_tags \u001b[38;5;241m=\u001b[39m RegressorTags()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'super' object has no attribute '__sklearn_tags__'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import dagshub\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder, StandardScaler, OrdinalEncoder,\n",
    "    FunctionTransformer, MultiLabelBinarizer\n",
    ")\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# --- Feature Configuration ---\n",
    "single_opt = ['EdLevel', 'DevType', 'Country', 'AISelect', 'RemoteWork']\n",
    "multi_opt = ['Employment', 'CodingActivities', 'LanguageHaveWorkedWith',\n",
    "             'DatabaseHaveWorkedWith', 'PlatformHaveWorkedWith',\n",
    "             'WebframeHaveWorkedWith', 'MiscTechHaveWorkedWith']\n",
    "number = ['YearsCode', 'YearsCodePro', 'WorkExp']  # Numeric fields (exclude Age)\n",
    "ordinal = ['Age']  # Ordinal age feature\n",
    "\n",
    "# --- Improved Preprocessing Functions ---\n",
    "def split_multiselect(X):\n",
    "    \"\"\"Splits semicolon-separated strings into a binary matrix.\"\"\"\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X = X.iloc[:, 0]\n",
    "    elif not isinstance(X, pd.Series):\n",
    "        X = pd.Series(X)\n",
    "    lists = X.fillna('').str.split(';')\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    return mlb.fit_transform(lists)\n",
    "\n",
    "\n",
    "def convert_numeric_years(X):\n",
    "    \"\"\"Converts special string labels to numeric for years columns, handles 1D or 2D inputs.\"\"\"\n",
    "    arr = np.array(X)\n",
    "    # Single feature case\n",
    "    if arr.ndim == 1:\n",
    "        series = pd.Series(arr).replace({\n",
    "            'Less than 1 year': 0.5,\n",
    "            'More than 50 years': 51\n",
    "        })\n",
    "        return pd.to_numeric(series, errors='coerce').values.reshape(-1, 1)\n",
    "    # Multiple features: apply to each column\n",
    "    df = pd.DataFrame(arr)\n",
    "    for col in df.columns:\n",
    "        df[col] = pd.Series(df[col]).replace({\n",
    "            'Less than 1 year': 0.5,\n",
    "            'More than 50 years': 51\n",
    "        })\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    return df.values\n",
    "\n",
    "\n",
    "def build_preprocessor():\n",
    "    \"\"\"Builds a comprehensive preprocessor handling numeric, ordinal, categorical, and multi-select features.\"\"\"\n",
    "    # Numeric pipeline: convert special strings, impute, scale\n",
    "    num_pipeline = Pipeline([\n",
    "        ('convert', FunctionTransformer(convert_numeric_years, validate=False)),\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    # Ordinal pipeline for age\n",
    "    ord_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='Missing')),\n",
    "        ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "    ])\n",
    "\n",
    "    # Single-choice categorical pipeline\n",
    "    cat_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='Missing')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    ])\n",
    "\n",
    "    # Multi-select pipeline\n",
    "    multi_pipeline = Pipeline([\n",
    "        ('split', FunctionTransformer(split_multiselect, validate=False))\n",
    "    ])\n",
    "\n",
    "    # Assemble ColumnTransformer\n",
    "    transformer_list = []\n",
    "    transformer_list.append(('num', num_pipeline, number))\n",
    "    transformer_list.append(('ord', ord_pipeline, ordinal))\n",
    "    transformer_list.append(('cat', cat_pipeline, single_opt))\n",
    "    for col in multi_opt:\n",
    "        transformer_list.append((f'multi_{col}', multi_pipeline, [col]))\n",
    "\n",
    "    return ColumnTransformer(transformers=transformer_list, remainder='drop')\n",
    "\n",
    "# --- MLflow & DagsHub Initialization ---\n",
    "dagshub.init(\n",
    "    repo_owner='malhar.c.prajapati',\n",
    "    repo_name='Stack-overflow-survey-2024-salary-prediction',\n",
    "    mlflow=True\n",
    ")\n",
    "\n",
    "# --- Data Loading & Preparation ---\n",
    "print(\"Loading data...\")\n",
    "df = pd.read_csv('../data/raw/survey_results_public.csv', low_memory=False)\n",
    "all_features = single_opt + multi_opt + number + ordinal + ['ConvertedCompYearly']\n",
    "df = df.loc[:, df.columns.intersection(all_features + ['ConvertedCompYearly'])]\n",
    "# Drop rows with missing target\n",
    "(df.dropna(subset=['ConvertedCompYearly'], inplace=True))\n",
    "X = df.drop(columns=['ConvertedCompYearly'])\n",
    "y = np.log1p(df['ConvertedCompYearly'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "print(f\"Training on {len(X_train)} samples, testing on {len(X_test)} samples.\")\n",
    "\n",
    "# --- Preprocessor Test ---\n",
    "preprocessor = build_preprocessor()\n",
    "try:\n",
    "    preprocessor.fit_transform(X_train.head())\n",
    "    print(\"Preprocessor test passed.\")\n",
    "except Exception as e:\n",
    "    print(f\"Preprocessor error: {e}\")\n",
    "\n",
    "# --- Model & Hyperparameter Configuration ---\n",
    "models_and_params = {\n",
    "    'gbr': (GradientBoostingRegressor(random_state=42), {\n",
    "        'model__n_estimators': [100, 200, 300],\n",
    "        'model__max_depth': [3, 5, 7],\n",
    "        'model__learning_rate': [0.1, 0.05],\n",
    "        'model__subsample': [0.8, 1.0]\n",
    "    }),\n",
    "    'rf': (RandomForestRegressor(random_state=42), {\n",
    "        'model__n_estimators': [100, 200, 300],\n",
    "        'model__max_depth': [10, 20, None],\n",
    "        'model__min_samples_split': [2, 5],\n",
    "        'model__min_samples_leaf': [1, 2]\n",
    "    }),\n",
    "    'xgb': (XGBRegressor(random_state=42, eval_metric='mae'), {\n",
    "        'model__n_estimators': [100, 200],\n",
    "        'model__max_depth': [3, 5, 7],\n",
    "        'model__learning_rate': [0.1, 0.05],\n",
    "        'model__subsample': [0.8, 1.0],\n",
    "        'model__colsample_bytree': [0.8, 1.0]\n",
    "    }),\n",
    "    'lgbm': (LGBMRegressor(random_state=42), {\n",
    "        'model__n_estimators': [100, 200],\n",
    "        'model__max_depth': [3, 5, -1],\n",
    "        'model__learning_rate': [0.1, 0.05],\n",
    "        'model__num_leaves': [31, 63],\n",
    "        'model__subsample': [0.8, 1.0]\n",
    "    }),\n",
    "    'elasticnet': (ElasticNet(random_state=42), {\n",
    "        'model__alpha': [0.1, 1.0, 10.0],\n",
    "        'model__l1_ratio': [0.2, 0.5, 0.8]\n",
    "    })\n",
    "}\n",
    "\n",
    "# --- Training Loop ---\n",
    "for model_name, (estimator, params) in models_and_params.items():\n",
    "    full_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('selector', SelectKBest(score_func=f_regression, k='all')),\n",
    "        ('model', estimator)\n",
    "    ])\n",
    "    grid = GridSearchCV(\n",
    "        full_pipeline, params, cv=3,\n",
    "        scoring='neg_mean_absolute_error', verbose=1, n_jobs=-1\n",
    "    )\n",
    "    print(f\"\\n--- Training {model_name} ---\")\n",
    "    with mlflow.start_run(run_name=f\"GridSearch_{model_name}\") as run:\n",
    "        mlflow.log_param('model', model_name)\n",
    "        grid.fit(X_train, y_train)\n",
    "        best = grid.best_estimator_\n",
    "        y_pred = best.predict(X_test)\n",
    "        # Convert back to original scale\n",
    "        y_true = np.expm1(y_test)\n",
    "        y_pred_orig = np.expm1(y_pred)\n",
    "        metrics = {\n",
    "            'mae': mean_absolute_error(y_true, y_pred_orig),\n",
    "            'rmse': np.sqrt(mean_squared_error(y_true, y_pred_orig)),\n",
    "            'r2': r2_score(y_true, y_pred_orig)\n",
    "        }\n",
    "        mlflow.log_params(grid.best_params_)\n",
    "        mlflow.log_metrics(metrics)\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=best,\n",
    "            artifact_path='model',\n",
    "            registered_model_name=f\"{model_name}_salary_predictor\"\n",
    "        )\n",
    "        print(f\"Results for {model_name}: {metrics}\")\n",
    "print(\"\\nAll models complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5142cbd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository malhar.c.prajapati/Stack-overflow-survey-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-salary-prediction initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository malhar.c.prajapati/Stack-overflow-survey-\u001b[1;36m2024\u001b[0m-salary-prediction initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-processed data...\n",
      "Data loaded. Training on 18748 samples, testing on 4687 samples.\n",
      "\n",
      "--- Starting GridSearchCV for rf ---\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in expm1\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Temp\\ipykernel_13992\\2479324611.py:81: RuntimeWarning: overflow encountered in expm1\n",
      "  y_pred_orig = np.expm1(y_pred_log)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run GridSearch_rf_on_processed_data at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0/runs/6f9ff02e87764aa2ada7058466fadbe6\n",
      "🧪 View experiment at: https://dagshub.com/malhar.c.prajapati/Stack-overflow-survey-2024-salary-prediction.mlflow/#/experiments/0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 84\u001b[0m\n\u001b[0;32m     80\u001b[0m y_test_orig \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpm1(y_test)\n\u001b[0;32m     81\u001b[0m y_pred_orig \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpm1(y_pred_log)\n\u001b[0;32m     83\u001b[0m metrics \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m---> 84\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mmean_absolute_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test_orig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_orig\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39msqrt(mean_squared_error(y_test_orig, y_pred_orig)),\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2\u001b[39m\u001b[38;5;124m'\u001b[39m: r2_score(y_test_orig, y_pred_orig)\n\u001b[0;32m     87\u001b[0m }\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- Results for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Params: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_search\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:277\u001b[0m, in \u001b[0;36mmean_absolute_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Mean absolute error regression loss.\u001b[39;00m\n\u001b[0;32m    223\u001b[0m \n\u001b[0;32m    224\u001b[0m \u001b[38;5;124;03mRead more in the :ref:`User Guide <mean_absolute_error>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;124;03m0.85...\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    274\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred, sample_weight, multioutput)\n\u001b[0;32m    276\u001b[0m _, y_true, y_pred, sample_weight, multioutput \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 277\u001b[0m     \u001b[43m_check_reg_targets_with_floating_dtype\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    280\u001b[0m )\n\u001b[0;32m    282\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    284\u001b[0m output_errors \u001b[38;5;241m=\u001b[39m _average(\n\u001b[0;32m    285\u001b[0m     xp\u001b[38;5;241m.\u001b[39mabs(y_pred \u001b[38;5;241m-\u001b[39m y_true), weights\u001b[38;5;241m=\u001b[39msample_weight, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, xp\u001b[38;5;241m=\u001b[39mxp\n\u001b[0;32m    286\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:198\u001b[0m, in \u001b[0;36m_check_reg_targets_with_floating_dtype\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, xp)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Ensures that y_true, y_pred, and sample_weight correspond to the same\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;124;03mregression task.\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;124;03m    correct keyword.\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    196\u001b[0m dtype_name \u001b[38;5;241m=\u001b[39m _find_matching_floating_dtype(y_true, y_pred, sample_weight, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[1;32m--> 198\u001b[0m y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;66;03m# _check_reg_targets does not accept sample_weight as input.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;66;03m# Convert sample_weight's data type separately to match dtype_name.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:105\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype, xp)\u001b[0m\n\u001b[0;32m    102\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred, multioutput, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m    104\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[1;32m--> 105\u001b[0m y_true \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1107\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1103\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[1;32m-> 1107\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m   1115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m   1116\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:120\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MALHAR PRAJAPATI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:169\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    155\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    168\u001b[0m     )\n\u001b[1;32m--> 169\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import dagshub\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "dagshub.init(\n",
    "    repo_owner='malhar.c.prajapati',\n",
    "    repo_name='Stack-overflow-survey-2024-salary-prediction',\n",
    "    mlflow=True\n",
    ")\n",
    "\n",
    "print(\"Loading pre-processed data...\")\n",
    "df = pd.read_csv('../data/processed/final_dataset.csv', index_col=0)\n",
    "X = df.drop(columns=['ConvertedCompYearly'])\n",
    "y = df['ConvertedCompYearly'] \n",
    "\n",
    "if len(X) != len(y):\n",
    "    raise ValueError(\n",
    "        f\"Mismatch in number of samples between processed features ({len(X)}) \"\n",
    "        f\"and target variable ({len(y)}). Please regenerate processed.csv.\"\n",
    "    )\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "print(f\"Data loaded. Training on {len(X_train)} samples, testing on {len(X_test)} samples.\")\n",
    "\n",
    "models_and_params = {\n",
    "    'rf': (RandomForestRegressor(random_state=42, n_jobs=-1), {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [10, 20],\n",
    "        'min_samples_leaf': [2, 4]\n",
    "    }),\n",
    "    'lgbm': (LGBMRegressor(random_state=42, n_jobs=-1), {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.05, 0.1],\n",
    "        'num_leaves': [31, 60]\n",
    "    }),\n",
    "    'xgb': (XGBRegressor(random_state=42, n_jobs=-1, eval_metric='mae'), {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.05, 0.1],\n",
    "        'max_depth': [3, 5]\n",
    "    }),\n",
    "    'gbr': (GradientBoostingRegressor(random_state=42), {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.05, 0.1],\n",
    "        'max_depth': [3, 5]\n",
    "    })\n",
    "}\n",
    "\n",
    "for model_name, (estimator, params) in models_and_params.items():\n",
    "    \n",
    "    full_pipeline = Pipeline([\n",
    "        ('model', estimator)\n",
    "    ])\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=estimator, \n",
    "        param_grid=params, \n",
    "        cv=3,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        verbose=1, \n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n--- Starting GridSearchCV for {model_name} ---\")\n",
    "    \n",
    "    with mlflow.start_run(run_name=f\"GridSearch_{model_name}_on_processed_data\") as run:\n",
    "        mlflow.log_param('model_name', model_name)\n",
    "        \n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred_log = best_model.predict(X_test)\n",
    "        y_test_orig = np.expm1(y_test)\n",
    "        y_pred_orig = np.expm1(y_pred_log)\n",
    "        \n",
    "        metrics = {\n",
    "            'mae': mean_absolute_error(y_test_orig, y_pred_orig),\n",
    "            'rmse': np.sqrt(mean_squared_error(y_test_orig, y_pred_orig)),\n",
    "            'r2': r2_score(y_test_orig, y_pred_orig)\n",
    "        }\n",
    "        \n",
    "        print(f\"--- Results for {model_name} ---\")\n",
    "        print(f\"Best Params: {grid_search.best_params_}\")\n",
    "        print(f\"Metrics: {metrics}\")\n",
    "        \n",
    "        \n",
    "        mlflow.log_params(grid_search.best_params_)\n",
    "        mlflow.log_metrics(metrics)\n",
    "        \n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=best_model,\n",
    "            artifact_path='model',\n",
    "            registered_model_name=f\"{model_name}_salary_predictor_processed\"\n",
    "        )\n",
    "\n",
    "print(\"\\n--- All model training experiments are complete. ---\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
